{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-04T16:30:52.582922Z",
     "start_time": "2025-02-04T16:30:51.864742Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from tqdm.notebook import tqdm\n",
    "from rca import make_binary_scoring, make_multiclass_scoring, process_categorical, best_logistic_solver, checker"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop feature_overlap because it contains many NaNs and compo_attribs because it doesn't have a large enough vocabulary and is also a identical to a 65 of the norms in the psychNorms dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-04T16:31:13.957559Z",
     "start_time": "2025-02-04T16:30:52.586473Z"
    }
   },
   "source": [
    "with open('../../data/brain_behav_union.pkl', 'rb') as f:\n",
    "    brain_behav_union = pickle.load(f)\n",
    "\n",
    "# Loading dictionary of dtype to embed\n",
    "with open('../../data/dtype_to_embed.json', 'r') as f:\n",
    "    dtype_to_embed = json.load(f)\n",
    "    \n",
    "brain_behav_names = dtype_to_embed['brain'] + dtype_to_embed['behavior']\n",
    "\n",
    "# Pulling and standardising embeddings\n",
    "embeds = {}\n",
    "embeds_path = '../../data/embeds/'\n",
    "for f_name in tqdm(os.listdir(embeds_path)):\n",
    "    if f_name not in ['feature_overlap.csv', 'compo_attribs.csv']:  # dropping since contains many NaNs\n",
    "        \n",
    "        embed = pd.read_csv(embeds_path + f_name, index_col=0)\n",
    "        embed_name = f_name.split('.')[0]\n",
    "        \n",
    "        # Subsetting to brain and behavior vocab\n",
    "        embed = embed.loc[embed.index.intersection(brain_behav_union)]\n",
    "        \n",
    "        # Standardising\n",
    "        embeds[embed_name] = (embed - embed.mean()) / embed.std()\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "933a9386fb80411985dbdcde489b826f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'fMRI_text_hyper_align': (1205, 1000),\n",
       " 'norms_sensorimotor': (36854, 11),\n",
       " 'EEG_text': (3355, 104),\n",
       " 'LexVec_CommonCrawl': (44082, 300),\n",
       " 'fastText_CommonCrawl': (44443, 300),\n",
       " 'spherical_text_Wikipedia': (35533, 300),\n",
       " 'GloVe_CommonCrawl': (44278, 300),\n",
       " 'EEG_speech': (1591, 130),\n",
       " 'PPMI_SVD_South_Florida': (4959, 300),\n",
       " 'THINGS': (1562, 49),\n",
       " 'fMRI_speech_hyper_align': (579, 6),\n",
       " 'CBOW_GoogleNews': (42830, 300),\n",
       " 'morphoNLM': (32769, 50),\n",
       " 'microarray': (626, 15),\n",
       " 'PPMI_SVD_SouthFlorida': (4959, 300),\n",
       " 'fastText_Wiki_News': (43143, 300),\n",
       " 'fastTextSub_OpenSub': (40607, 300),\n",
       " 'SGSoftMaxOutput_SWOW': (25442, 300),\n",
       " 'PPMI_SVD_SWOW': (11783, 300),\n",
       " 'GloVe_Twitter': (32947, 200),\n",
       " 'GloVe_Wikipedia': (39421, 300),\n",
       " 'eye_tracking': (7486, 6),\n",
       " 'SGSoftMaxInput_SWOW': (11783, 300),\n",
       " 'SVD_sim_rel': (6837, 300),\n",
       " 'PPMI_SVD_EAT': (7775, 300)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T16:31:14.058769Z",
     "start_time": "2025-02-04T16:31:14.055165Z"
    }
   },
   "source": [
    "with open('../../data/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_to_type"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBOW_GoogleNews': 'text',\n",
       " 'fastText_CommonCrawl': 'text',\n",
       " 'fastText_Wiki_News': 'text',\n",
       " 'fastTextSub_OpenSub': 'text',\n",
       " 'GloVe_CommonCrawl': 'text',\n",
       " 'GloVe_Twitter': 'text',\n",
       " 'GloVe_Wikipedia': 'text',\n",
       " 'LexVec_CommonCrawl': 'text',\n",
       " 'morphoNLM': 'text',\n",
       " 'spherical_text_Wikipedia': 'text',\n",
       " 'eye_tracking': 'brain',\n",
       " 'EEG_speech': 'brain',\n",
       " 'EEG_text': 'brain',\n",
       " 'fMRI_speech_hyper_align': 'brain',\n",
       " 'fMRI_text_hyper_align': 'brain',\n",
       " 'microarray': 'brain',\n",
       " 'PPMI_SVD_SWOW': 'behavior',\n",
       " 'SGSoftMaxInput_SWOW': 'behavior',\n",
       " 'SGSoftMaxOutput_SWOW': 'behavior',\n",
       " 'PPMI_SVD_SouthFlorida': 'behavior',\n",
       " 'PPMI_SVD_EAT': 'behavior',\n",
       " 'THINGS': 'behavior',\n",
       " 'feature_overlap': 'behavior',\n",
       " 'norms_sensorimotor': 'behavior',\n",
       " 'compo_attribs': 'behavior',\n",
       " 'SVD_sim_rel': 'behavior'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-04T16:31:15.817311Z",
     "start_time": "2025-02-04T16:31:14.083128Z"
    }
   },
   "source": [
    "# Loading norms\n",
    "norms = pd.read_csv('../../data/psychNorms/psychNorms_processed.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norm_meta = pd.read_csv('../../data/psychNorms/psychNorms_metadata_processed.csv', index_col='norm')\n",
    "norms"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             frequency_lund  frequency_kucera  frequency_subtlexus  \\\n",
       "word                                                                 \n",
       "'em                     0.0               NaN                  NaN   \n",
       "'neath                  0.0               NaN                  NaN   \n",
       "'re                     0.0               NaN                  NaN   \n",
       "'shun                   0.0               NaN                  NaN   \n",
       "'tis                    0.0               NaN                  NaN   \n",
       "...                     ...               ...                  ...   \n",
       "shrick                  NaN               NaN                  NaN   \n",
       "post office             NaN               NaN                  NaN   \n",
       "fishing rod             NaN               NaN                  NaN   \n",
       "March                   NaN               NaN                  NaN   \n",
       "May                     NaN               NaN                  NaN   \n",
       "\n",
       "             frequency_subtlexuk  frequency_blog_gimenes  \\\n",
       "word                                                       \n",
       "'em                          NaN                     NaN   \n",
       "'neath                       NaN                     NaN   \n",
       "'re                          NaN                     NaN   \n",
       "'shun                        NaN                     NaN   \n",
       "'tis                         NaN                     NaN   \n",
       "...                          ...                     ...   \n",
       "shrick                       NaN                     NaN   \n",
       "post office                  NaN                     NaN   \n",
       "fishing rod                  NaN                     NaN   \n",
       "March                        NaN                     NaN   \n",
       "May                          NaN                     NaN   \n",
       "\n",
       "             frequency_twitter_gimenes  frequency_news_gimenes  \\\n",
       "word                                                             \n",
       "'em                                NaN                     NaN   \n",
       "'neath                             NaN                     NaN   \n",
       "'re                                NaN                     NaN   \n",
       "'shun                              NaN                     NaN   \n",
       "'tis                               NaN                     NaN   \n",
       "...                                ...                     ...   \n",
       "shrick                             NaN                     NaN   \n",
       "post office                        NaN                     NaN   \n",
       "fishing rod                        NaN                     NaN   \n",
       "March                              NaN                     NaN   \n",
       "May                                NaN                     NaN   \n",
       "\n",
       "             frequency_written_cobuild  frequency_spoken_cobuild  \\\n",
       "word                                                               \n",
       "'em                             1.3617                    1.9138   \n",
       "'neath                          0.0000                    0.0000   \n",
       "'re                             0.9031                    1.6335   \n",
       "'shun                           0.0000                    0.0000   \n",
       "'tis                            0.4771                    0.6021   \n",
       "...                                ...                       ...   \n",
       "shrick                             NaN                       NaN   \n",
       "post office                        NaN                       NaN   \n",
       "fishing rod                        NaN                       NaN   \n",
       "March                              NaN                       NaN   \n",
       "May                                NaN                       NaN   \n",
       "\n",
       "             context_diversity_subtlexus  ...  person_vanarsdall  \\\n",
       "word                                      ...                      \n",
       "'em                                  NaN  ...                NaN   \n",
       "'neath                               NaN  ...                NaN   \n",
       "'re                                  NaN  ...                NaN   \n",
       "'shun                                NaN  ...                NaN   \n",
       "'tis                                 NaN  ...                NaN   \n",
       "...                                  ...  ...                ...   \n",
       "shrick                               NaN  ...                NaN   \n",
       "post office                          NaN  ...                NaN   \n",
       "fishing rod                          NaN  ...                NaN   \n",
       "March                                NaN  ...                NaN   \n",
       "May                                  NaN  ...                NaN   \n",
       "\n",
       "             goals_vanarsdall  movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "word                                                                          \n",
       "'em                       NaN                  NaN                      NaN   \n",
       "'neath                    NaN                  NaN                      NaN   \n",
       "'re                       NaN                  NaN                      NaN   \n",
       "'shun                     NaN                  NaN                      NaN   \n",
       "'tis                      NaN                  NaN                      NaN   \n",
       "...                       ...                  ...                      ...   \n",
       "shrick                    NaN                  NaN                      NaN   \n",
       "post office               NaN                  NaN                      NaN   \n",
       "fishing rod               NaN                  NaN                      NaN   \n",
       "March                     NaN                  NaN                      NaN   \n",
       "May                       NaN                  NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "word                                                           \n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \\\n",
       "word                                                         \n",
       "'em                       NaN       NaN                NaN   \n",
       "'neath                    NaN       NaN                NaN   \n",
       "'re                       NaN       NaN                NaN   \n",
       "'shun                     NaN       NaN                NaN   \n",
       "'tis                      NaN       NaN                NaN   \n",
       "...                       ...       ...                ...   \n",
       "shrick                   2.62      4.38               2.93   \n",
       "post office              3.79      3.07               5.29   \n",
       "fishing rod              2.29      3.38               5.64   \n",
       "March                    3.43      2.76               3.50   \n",
       "May                      4.10      2.86               2.79   \n",
       "\n",
       "             sensory_experience_juhasz2013  \n",
       "word                                        \n",
       "'em                                    NaN  \n",
       "'neath                                 NaN  \n",
       "'re                                    NaN  \n",
       "'shun                                  NaN  \n",
       "'tis                                   NaN  \n",
       "...                                    ...  \n",
       "shrick                                 NaN  \n",
       "post office                            NaN  \n",
       "fishing rod                            NaN  \n",
       "March                                  NaN  \n",
       "May                                    NaN  \n",
       "\n",
       "[107085 rows x 291 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_lund</th>\n",
       "      <th>frequency_kucera</th>\n",
       "      <th>frequency_subtlexus</th>\n",
       "      <th>frequency_subtlexuk</th>\n",
       "      <th>frequency_blog_gimenes</th>\n",
       "      <th>frequency_twitter_gimenes</th>\n",
       "      <th>frequency_news_gimenes</th>\n",
       "      <th>frequency_written_cobuild</th>\n",
       "      <th>frequency_spoken_cobuild</th>\n",
       "      <th>context_diversity_subtlexus</th>\n",
       "      <th>...</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "      <th>sensory_experience_juhasz2013</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows Ã— 291 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-02-04T16:31:25.198876Z",
     "start_time": "2025-02-04T16:31:15.885135Z"
    }
   },
   "source": [
    "# Ridge\n",
    "min_ord, max_ord = -5, 5\n",
    "alphas = np.logspace(\n",
    "    min_ord, max_ord, max_ord - min_ord + 1\n",
    ")\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = 'r2'\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 10\n",
    "\n",
    "# RCA\n",
    "rca = []\n",
    "for embed_name in tqdm(embeds.keys()):\n",
    "    embed = embeds[embed_name]\n",
    "    \n",
    "    to_print = []\n",
    "    for norm_name in tqdm(norms.columns, desc=embed_name):\n",
    "        \n",
    "        # Aligning data\n",
    "        y = norms[norm_name].dropna()\n",
    "        X, y = embed.align(y, axis=0, join='inner', copy=True) \n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = norm_meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators\n",
    "        if norm_dtype in ['binary', 'multiclass']:\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(X, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv),\n",
    "                solver=solver, n_jobs=8\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "  \n",
    "        # Cross validation\n",
    "        associated_embed = norm_meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(embed_name, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            r2s = cross_val_score(estimator, X, y, cv=outer_cv, scoring=scoring, n_jobs=n_jobs) # stratification is automatically used for classification\n",
    "            r2_mean, r2_sd = r2s.mean(), r2s.std()\n",
    "        else:\n",
    "            r2_mean, r2_sd = np.nan, np.nan\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(X))\n",
    "        test_n = len(X) - train_n\n",
    "        p = X.shape[1]\n",
    "        embed_type = embed_to_type[embed_name]\n",
    "        rca.append([\n",
    "            embed_name, embed_type, norm_name, train_n, test_n, p, \n",
    "            r2_mean, r2_sd, check\n",
    "        ])\n",
    "        \n",
    "        to_print.append([norm_name, train_n, r2_mean, r2_sd, check])\n",
    "            \n",
    "            \n",
    "    to_print = pd.DataFrame(to_print, columns=['norm' , 'train_n', 'r2_mean', 'r2_sd', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10))\n",
    "\n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'embed_type', 'norm', 'train_n', 'test_n', 'p', \n",
    "        'r2_mean', 'r2_sd', 'check'\n",
    "    ]\n",
    ")\n",
    "\n",
    "rca.to_csv('../../data/results/rca.csv', index=False)\n",
    "rca"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "777d6058a37e4fb183e5bd942247d500"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fMRI_text_hyper_align:   0%|          | 0/291 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21d946a7dc5841d793b6e4e536e62c6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 59\u001B[0m\n\u001B[1;32m     57\u001B[0m check \u001B[38;5;241m=\u001B[39m checker(embed_name, y, norm_dtype, associated_embed, outer_cv)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 59\u001B[0m     r2s \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# stratification is automatically used for classification\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     r2_mean, r2_sd \u001B[38;5;241m=\u001B[39m r2s\u001B[38;5;241m.\u001B[39mmean(), r2s\u001B[38;5;241m.\u001B[39mstd()\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/psychProbingEnv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/psychProbingEnv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/psychProbingEnv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/psychProbingEnv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/psychProbingEnv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[1;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[1;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
