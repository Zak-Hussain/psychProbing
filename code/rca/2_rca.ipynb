{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from rca import make_binary_scoring, make_multiclass_scoring, process_categorical, best_logistic_solver, checker, k_fold_cross_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T10:55:46.383195Z",
     "start_time": "2025-01-09T10:55:46.362435Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": "## Preparing embeds",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We drop feature_overlap because it contains many NaNs and compo_attribs because it doesn't have a large enough vocabulary and is also a identical to a 65 of the norms in the psychNorms dataset."
  },
  {
   "cell_type": "code",
   "source": [
    "with open('../../data/brain_behav_union.pkl', 'rb') as f:\n",
    "    brain_behav_union = pickle.load(f)\n",
    "\n",
    "# Loading dictionary of dtype to embed\n",
    "with open('../../data/dtype_to_embed.json', 'r') as f:\n",
    "    dtype_to_embed = json.load(f)\n",
    "    \n",
    "brain_behav_names = dtype_to_embed['brain'] + dtype_to_embed['behavior']\n",
    "\n",
    "# Pulling and standardising embeddings\n",
    "embeds = {}\n",
    "embeds_path = '../../data/embeds/'\n",
    "for f_name in tqdm(os.listdir(embeds_path)):\n",
    "    if f_name not in ['feature_overlap.csv', 'compo_attribs.csv']:  # dropping since contains many NaNs\n",
    "        \n",
    "        embed = pd.read_csv(embeds_path + f_name, index_col=0)\n",
    "        embed_name = f_name.split('.')[0]\n",
    "        \n",
    "        # Subsetting to brain and behavior vocab\n",
    "        embed = embed.loc[embed.index.intersection(brain_behav_union)]\n",
    "        \n",
    "        # Standardising\n",
    "        embeds[embed_name] = (embed - embed.mean()) / embed.std()\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:20:11.246498Z",
     "start_time": "2024-09-24T09:19:50.412525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a979b6161e9648418b6d9701ac95882a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'fMRI_text_hyper_align': (1205, 1000),\n",
       " 'norms_sensorimotor': (36854, 11),\n",
       " 'EEG_text': (3355, 104),\n",
       " 'LexVec_CommonCrawl': (44082, 300),\n",
       " 'fastText_CommonCrawl': (44443, 300),\n",
       " 'spherical_text_Wikipedia': (35533, 300),\n",
       " 'GloVe_CommonCrawl': (44278, 300),\n",
       " 'EEG_speech': (1591, 130),\n",
       " 'THINGS': (1562, 49),\n",
       " 'fMRI_speech_hyper_align': (579, 6),\n",
       " 'CBOW_GoogleNews': (42830, 300),\n",
       " 'morphoNLM': (32769, 50),\n",
       " 'microarray': (626, 15),\n",
       " 'PPMI_SVD_SouthFlorida': (4959, 300),\n",
       " 'fastText_Wiki_News': (43143, 300),\n",
       " 'fastTextSub_OpenSub': (40607, 300),\n",
       " 'SGSoftMaxOutput_SWOW': (25442, 300),\n",
       " 'PPMI_SVD_SWOW': (11783, 300),\n",
       " 'GloVe_Twitter': (32947, 200),\n",
       " 'GloVe_Wikipedia': (39421, 300),\n",
       " 'eye_tracking': (7486, 6),\n",
       " 'SGSoftMaxInput_SWOW': (11783, 300),\n",
       " 'SVD_sim_rel': (6002, 300),\n",
       " 'PPMI_SVD_EAT': (7775, 300)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('../../data/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_to_type"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing norms"
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading norms\n",
    "norms = pd.read_csv('../../data/psychNorms/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norm_meta = pd.read_csv('../../data/psychNorms/psychNorms_metadata.csv', index_col='norm')\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T11:08:17.504453Z",
     "start_time": "2025-01-09T11:08:15.523345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             frequency_lund  frequency_kucera  frequency_subtlexus  \\\n",
       "word                                                                 \n",
       "'em                     0.0               NaN                  NaN   \n",
       "'neath                  0.0               NaN                  NaN   \n",
       "'re                     0.0               NaN                  NaN   \n",
       "'shun                   0.0               NaN                  NaN   \n",
       "'tis                    0.0               NaN                  NaN   \n",
       "...                     ...               ...                  ...   \n",
       "shrick                  NaN               NaN                  NaN   \n",
       "post office             NaN               NaN                  NaN   \n",
       "fishing rod             NaN               NaN                  NaN   \n",
       "March                   NaN               NaN                  NaN   \n",
       "May                     NaN               NaN                  NaN   \n",
       "\n",
       "             frequency_subtlexuk  frequency_blog_gimenes  \\\n",
       "word                                                       \n",
       "'em                          NaN                     NaN   \n",
       "'neath                       NaN                     NaN   \n",
       "'re                          NaN                     NaN   \n",
       "'shun                        NaN                     NaN   \n",
       "'tis                         NaN                     NaN   \n",
       "...                          ...                     ...   \n",
       "shrick                       NaN                     NaN   \n",
       "post office                  NaN                     NaN   \n",
       "fishing rod                  NaN                     NaN   \n",
       "March                        NaN                     NaN   \n",
       "May                          NaN                     NaN   \n",
       "\n",
       "             frequency_twitter_gimenes  frequency_news_gimenes  \\\n",
       "word                                                             \n",
       "'em                                NaN                     NaN   \n",
       "'neath                             NaN                     NaN   \n",
       "'re                                NaN                     NaN   \n",
       "'shun                              NaN                     NaN   \n",
       "'tis                               NaN                     NaN   \n",
       "...                                ...                     ...   \n",
       "shrick                             NaN                     NaN   \n",
       "post office                        NaN                     NaN   \n",
       "fishing rod                        NaN                     NaN   \n",
       "March                              NaN                     NaN   \n",
       "May                                NaN                     NaN   \n",
       "\n",
       "             frequency_written_cobuild  frequency_spoken_cobuild  \\\n",
       "word                                                               \n",
       "'em                             1.3617                    1.9138   \n",
       "'neath                          0.0000                    0.0000   \n",
       "'re                             0.9031                    1.6335   \n",
       "'shun                           0.0000                    0.0000   \n",
       "'tis                            0.4771                    0.6021   \n",
       "...                                ...                       ...   \n",
       "shrick                             NaN                       NaN   \n",
       "post office                        NaN                       NaN   \n",
       "fishing rod                        NaN                       NaN   \n",
       "March                              NaN                       NaN   \n",
       "May                                NaN                       NaN   \n",
       "\n",
       "             context_diversity_subtlexus  ...  person_vanarsdall  \\\n",
       "word                                      ...                      \n",
       "'em                                  NaN  ...                NaN   \n",
       "'neath                               NaN  ...                NaN   \n",
       "'re                                  NaN  ...                NaN   \n",
       "'shun                                NaN  ...                NaN   \n",
       "'tis                                 NaN  ...                NaN   \n",
       "...                                  ...  ...                ...   \n",
       "shrick                               NaN  ...                NaN   \n",
       "post office                          NaN  ...                NaN   \n",
       "fishing rod                          NaN  ...                NaN   \n",
       "March                                NaN  ...                NaN   \n",
       "May                                  NaN  ...                NaN   \n",
       "\n",
       "             goals_vanarsdall  movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "word                                                                          \n",
       "'em                       NaN                  NaN                      NaN   \n",
       "'neath                    NaN                  NaN                      NaN   \n",
       "'re                       NaN                  NaN                      NaN   \n",
       "'shun                     NaN                  NaN                      NaN   \n",
       "'tis                      NaN                  NaN                      NaN   \n",
       "...                       ...                  ...                      ...   \n",
       "shrick                    NaN                  NaN                      NaN   \n",
       "post office               NaN                  NaN                      NaN   \n",
       "fishing rod               NaN                  NaN                      NaN   \n",
       "March                     NaN                  NaN                      NaN   \n",
       "May                       NaN                  NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "word                                                           \n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \\\n",
       "word                                                         \n",
       "'em                       NaN       NaN                NaN   \n",
       "'neath                    NaN       NaN                NaN   \n",
       "'re                       NaN       NaN                NaN   \n",
       "'shun                     NaN       NaN                NaN   \n",
       "'tis                      NaN       NaN                NaN   \n",
       "...                       ...       ...                ...   \n",
       "shrick                   2.62      4.38               2.93   \n",
       "post office              3.79      3.07               5.29   \n",
       "fishing rod              2.29      3.38               5.64   \n",
       "March                    3.43      2.76               3.50   \n",
       "May                      4.10      2.86               2.79   \n",
       "\n",
       "             sensory_experience_juhasz2013  \n",
       "word                                        \n",
       "'em                                    NaN  \n",
       "'neath                                 NaN  \n",
       "'re                                    NaN  \n",
       "'shun                                  NaN  \n",
       "'tis                                   NaN  \n",
       "...                                    ...  \n",
       "shrick                                 NaN  \n",
       "post office                            NaN  \n",
       "fishing rod                            NaN  \n",
       "March                                  NaN  \n",
       "May                                    NaN  \n",
       "\n",
       "[107085 rows x 291 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_lund</th>\n",
       "      <th>frequency_kucera</th>\n",
       "      <th>frequency_subtlexus</th>\n",
       "      <th>frequency_subtlexuk</th>\n",
       "      <th>frequency_blog_gimenes</th>\n",
       "      <th>frequency_twitter_gimenes</th>\n",
       "      <th>frequency_news_gimenes</th>\n",
       "      <th>frequency_written_cobuild</th>\n",
       "      <th>frequency_spoken_cobuild</th>\n",
       "      <th>context_diversity_subtlexus</th>\n",
       "      <th>...</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "      <th>sensory_experience_juhasz2013</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows × 291 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:08:19.416767Z",
     "start_time": "2025-01-09T11:08:19.233275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding 'associated_embed' to metadata to avoid data leakage\n",
    "norm_meta['associated_embed'] = np.nan\n",
    "norm_meta['associated_embed'][norm_meta.index.str.contains('_lancaster')] = 'norms_sensorimotor'\n",
    "norm_meta['associated_embed'][norm_meta.index == 'association_frequency_dedeyne'] = 'PPMI_SVD_SWOW SGSoftMaxInput_SWOW SGSoftMaxOutput_SWOW'\n",
    "\n",
    "# Adding 'type' to metadata (numeric, binary, multiclass)\n",
    "norm_meta['type'] = [type_of_target(norms[name].dropna()) for name in norm_meta.index]\n",
    "norm_meta['type'] = norm_meta['type'].replace('continuous', 'numeric')\n",
    "\n",
    "# Manually fixing mistyped norms\n",
    "numeric_norms = [\n",
    "    'n_senses_wordnet_miller', 'n_senses_wordsmyth_rice', 'n_meanings_websters_gao', 'n_features_buchanan',\n",
    "    'n_semantic_neighbors_shaoul', 'association_frequency_dedeyne', 'cue_setsize_nelson', 'difficulty_rudell',\n",
    "    'likableness_anderson', 'meaningfulness_anderson'\n",
    "]\n",
    "for norm in norm_meta.index:\n",
    "    if 'vanarsdall' in norm:\n",
    "        numeric_norms.append(norm)\n",
    "        \n",
    "norm_meta.loc[numeric_norms, 'type'] = 'numeric'\n",
    "\n",
    "# Saving metadata\n",
    "norm_meta.to_csv('../../data/psychNorms/psychNorms_metadata_processed.csv')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/5gbrfvhn687dxwjl5_xg21t40000gq/T/ipykernel_46204/1322054375.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  norm_meta['associated_embed'][norm_meta.index.str.contains('_lancaster')] = 'norms_sensorimotor'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:20:19.919244Z",
     "start_time": "2024-09-24T09:20:18.108412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Log transforming selected norms\n",
    "norms_to_log = pd.read_csv('../../data/norms_to_log.csv')['norm']\n",
    "norms[norms_to_log] = norms[norms_to_log].apply(np.log1p)\n",
    "norms_to_log"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Nsenses_WordNet\n",
       "1           Nsenses_Wordsmyth\n",
       "2         Nmeanings_Wordsmyth\n",
       "3          Nmeanings_Websters\n",
       "4                   NFeatures\n",
       "5                       Sem_N\n",
       "6         Assoc_Freq_Token123\n",
       "7                 Cue_SetSize\n",
       "8           LexicalD_RT_V_ELP\n",
       "9           LexicalD_RT_V_ECP\n",
       "10          LexicalD_RT_V_BLP\n",
       "11         LexicalD_RT_A_MALD\n",
       "12         LexicalD_RT_A_AELP\n",
       "13              Naming_RT_ELP\n",
       "14       SemanticD_RT_Calgary\n",
       "15                  rt_khanna\n",
       "16                     rt_ley\n",
       "17               rt_chiarello\n",
       "18                    rt_chen\n",
       "19             aoa_rt_cortese\n",
       "20    imageability_rt_cortese\n",
       "21                  rt_schock\n",
       "Name: norm, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "min_ord, max_ord = -5, 5\n",
    "alphas = np.logspace(\n",
    "    min_ord, max_ord, max_ord - min_ord + 1\n",
    ")\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for embed_name in tqdm(embeds.keys()):\n",
    "    embed = embeds[embed_name]\n",
    "    \n",
    "    to_print = []\n",
    "    for norm_name in tqdm(norms.columns, desc=embed_name):\n",
    "        \n",
    "        # Aligning data\n",
    "        y = norms[norm_name].dropna()\n",
    "        X, y = embed.align(y, axis=0, join='inner', copy=True) \n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = norm_meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators\n",
    "        if norm_dtype in ['binary', 'multiclass']:\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(X, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv),\n",
    "                solver=solver, n_jobs=8\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "  \n",
    "        # Cross validation\n",
    "        associated_embed = norm_meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(embed_name, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs) # stratification is automatically used for classification\n",
    "            r2s, mses = scores['test_r2'], - scores['test_neg_mse']\n",
    "            r2_mean, r2_sd = r2s.mean(), r2s.std()\n",
    "            mse_mean, mse_sd = mses.mean(), mses.std()\n",
    "        else:\n",
    "            r2_mean, r2_sd = np.nan, np.nan\n",
    "            mse_mean, mse_sd = np.nan, np.nan\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(X))\n",
    "        test_n = len(X) - train_n\n",
    "        p = X.shape[1]\n",
    "        embed_type = embed_to_type[embed_name]\n",
    "        rca.append([\n",
    "            embed_name, embed_type, norm_name, train_n, test_n, p, \n",
    "            r2_mean, r2_sd, mse_mean, mse_sd, check\n",
    "        ])\n",
    "        \n",
    "        to_print.append([norm_name, train_n, r2_mean, r2_sd, check])\n",
    "\n",
    "    to_print = pd.DataFrame(to_print, columns=['norm' , 'train_n', 'r2_mean', 'r2_sd', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10))\n",
    "\n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'embed_type', 'norm', 'train_n', 'test_n', 'p', \n",
    "        'r2_mean', 'r2_sd', 'mse_mean', 'mse_sd', 'check'\n",
    "    ]\n",
    ")\n",
    "\n",
    "rca.to_csv('../../data/results/rca.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
