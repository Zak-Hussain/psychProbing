{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from rca import make_binary_scoring, make_multiclass_scoring, process_categorical, best_logistic_solver, checker, k_fold_cross_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:19:45.523910Z",
     "start_time": "2024-09-24T09:19:44.068487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:19:50.410828Z",
     "start_time": "2024-09-24T09:19:45.525138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading dictionary of dtype to embed\n",
    "with open('../../data/dtype_to_embed.json', 'r') as f:\n",
    "    dtype_to_embed = json.load(f)\n",
    "    \n",
    "brain_behav_names = dtype_to_embed['brain'] + dtype_to_embed['behavior']\n",
    "\n",
    "# Iterating through embeds and finding union of all brain and behavior vocabs (embeds have already been subsetted to their intersection with the union of all the norm vocabs)\n",
    "embeds_path = '../../data/embeds/'\n",
    "brain_behav_union = set()\n",
    "for name in tqdm(brain_behav_names):\n",
    "    vocab = set(pd.read_csv(embeds_path + name + '.csv', index_col=0).index)\n",
    "    brain_behav_union = brain_behav_union.union(vocab)\n",
    "\n",
    "len(brain_behav_union)  "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd83d5f7a51f499f9b6a8e8fd7bdb597"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "46238"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We drop feature_overlap because it contains many NaNs and compo_attribs because it doesn't have a large enough vocabulary and is also a identical to a 65 of the norms in the psychNorms dataset."
  },
  {
   "cell_type": "code",
   "source": [
    "# Pulling and standardising embeddings\n",
    "embeds = {}\n",
    "embeds_path = '../../data/embeds/'\n",
    "for f_name in tqdm(os.listdir(embeds_path)):\n",
    "    if f_name not in ['feature_overlap.csv', 'compo_attribs.csv']:  # dropping since contains many NaNs\n",
    "        \n",
    "        embed = pd.read_csv(embeds_path + f_name, index_col=0)\n",
    "        embed_name = f_name.split('.')[0]\n",
    "        \n",
    "        # Subsetting to brain and behavior vocab\n",
    "        embed = embed.loc[embed.index.intersection(brain_behav_union)]\n",
    "        \n",
    "        # Standardising\n",
    "        embeds[embed_name] = (embed - embed.mean()) / embed.std()\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:20:11.246498Z",
     "start_time": "2024-09-24T09:19:50.412525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a979b6161e9648418b6d9701ac95882a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'fMRI_text_hyper_align': (1205, 1000),\n",
       " 'norms_sensorimotor': (36854, 11),\n",
       " 'EEG_text': (3355, 104),\n",
       " 'LexVec_CommonCrawl': (44082, 300),\n",
       " 'fastText_CommonCrawl': (44443, 300),\n",
       " 'spherical_text_Wikipedia': (35533, 300),\n",
       " 'GloVe_CommonCrawl': (44278, 300),\n",
       " 'EEG_speech': (1591, 130),\n",
       " 'THINGS': (1562, 49),\n",
       " 'fMRI_speech_hyper_align': (579, 6),\n",
       " 'CBOW_GoogleNews': (42830, 300),\n",
       " 'morphoNLM': (32769, 50),\n",
       " 'microarray': (626, 15),\n",
       " 'PPMI_SVD_SouthFlorida': (4959, 300),\n",
       " 'fastText_Wiki_News': (43143, 300),\n",
       " 'fastTextSub_OpenSub': (40607, 300),\n",
       " 'SGSoftMaxOutput_SWOW': (25442, 300),\n",
       " 'PPMI_SVD_SWOW': (11783, 300),\n",
       " 'GloVe_Twitter': (32947, 200),\n",
       " 'GloVe_Wikipedia': (39421, 300),\n",
       " 'eye_tracking': (7486, 6),\n",
       " 'SGSoftMaxInput_SWOW': (11783, 300),\n",
       " 'SVD_sim_rel': (6002, 300),\n",
       " 'PPMI_SVD_EAT': (7775, 300)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "norms = pd.read_csv('../../data/psychNorms/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norm_metadata = pd.read_csv('../../data/psychNorms/psychNorms_metadata.csv', index_col='norm')\n",
    "norm_metadata['associated_embed'] = norm_metadata['associated_embed'].astype(str)\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:20:12.964775Z",
     "start_time": "2024-09-24T09:20:11.247639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Freq_HAL  Freq_KF  Freq_SUBTLEXUS  Freq_SUBTLEXUK  Freq_Blog  \\\n",
       "'em               0.0      NaN             NaN             NaN        NaN   \n",
       "'neath            0.0      NaN             NaN             NaN        NaN   \n",
       "'re               0.0      NaN             NaN             NaN        NaN   \n",
       "'shun             0.0      NaN             NaN             NaN        NaN   \n",
       "'tis              0.0      NaN             NaN             NaN        NaN   \n",
       "...               ...      ...             ...             ...        ...   \n",
       "shrick            NaN      NaN             NaN             NaN        NaN   \n",
       "post office       NaN      NaN             NaN             NaN        NaN   \n",
       "fishing rod       NaN      NaN             NaN             NaN        NaN   \n",
       "March             NaN      NaN             NaN             NaN        NaN   \n",
       "May               NaN      NaN             NaN             NaN        NaN   \n",
       "\n",
       "             Freq_Twitter  Freq_News  Freq_CobW  Freq_CobS  CD_SUBTLEXUS  ...  \\\n",
       "'em                   NaN        NaN     1.3617     1.9138           NaN  ...   \n",
       "'neath                NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'re                   NaN        NaN     0.9031     1.6335           NaN  ...   \n",
       "'shun                 NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'tis                  NaN        NaN     0.4771     0.6021           NaN  ...   \n",
       "...                   ...        ...        ...        ...           ...  ...   \n",
       "shrick                NaN        NaN        NaN        NaN           NaN  ...   \n",
       "post office           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "fishing rod           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "March                 NaN        NaN        NaN        NaN           NaN  ...   \n",
       "May                   NaN        NaN        NaN        NaN           NaN  ...   \n",
       "\n",
       "             reproduction_vanarsdall  person_vanarsdall  goals_vanarsdall  \\\n",
       "'em                              NaN                NaN               NaN   \n",
       "'neath                           NaN                NaN               NaN   \n",
       "'re                              NaN                NaN               NaN   \n",
       "'shun                            NaN                NaN               NaN   \n",
       "'tis                             NaN                NaN               NaN   \n",
       "...                              ...                ...               ...   \n",
       "shrick                           NaN                NaN               NaN   \n",
       "post office                      NaN                NaN               NaN   \n",
       "fishing rod                      NaN                NaN               NaN   \n",
       "March                            NaN                NaN               NaN   \n",
       "May                              NaN                NaN               NaN   \n",
       "\n",
       "             movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "'em                          NaN                      NaN   \n",
       "'neath                       NaN                      NaN   \n",
       "'re                          NaN                      NaN   \n",
       "'shun                        NaN                      NaN   \n",
       "'tis                         NaN                      NaN   \n",
       "...                          ...                      ...   \n",
       "shrick                       NaN                      NaN   \n",
       "post office                  NaN                      NaN   \n",
       "fishing rod                  NaN                      NaN   \n",
       "March                        NaN                      NaN   \n",
       "May                          NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \n",
       "'em                       NaN       NaN                NaN  \n",
       "'neath                    NaN       NaN                NaN  \n",
       "'re                       NaN       NaN                NaN  \n",
       "'shun                     NaN       NaN                NaN  \n",
       "'tis                      NaN       NaN                NaN  \n",
       "...                       ...       ...                ...  \n",
       "shrick                   2.62      4.38               2.93  \n",
       "post office              3.79      3.07               5.29  \n",
       "fishing rod              2.29      3.38               5.64  \n",
       "March                    3.43      2.76               3.50  \n",
       "May                      4.10      2.86               2.79  \n",
       "\n",
       "[107085 rows x 292 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Freq_KF</th>\n",
       "      <th>Freq_SUBTLEXUS</th>\n",
       "      <th>Freq_SUBTLEXUK</th>\n",
       "      <th>Freq_Blog</th>\n",
       "      <th>Freq_Twitter</th>\n",
       "      <th>Freq_News</th>\n",
       "      <th>Freq_CobW</th>\n",
       "      <th>Freq_CobS</th>\n",
       "      <th>CD_SUBTLEXUS</th>\n",
       "      <th>...</th>\n",
       "      <th>reproduction_vanarsdall</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows × 292 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:20:19.919244Z",
     "start_time": "2024-09-24T09:20:18.108412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../../data/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_to_type\n",
    "\n",
    "# Log transforming selected norms\n",
    "norms_to_log = pd.read_csv('../../data/norms_to_log.csv')['norm']\n",
    "norms[norms_to_log] = norms[norms_to_log].apply(np.log1p)\n",
    "norms_to_log"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Nsenses_WordNet\n",
       "1           Nsenses_Wordsmyth\n",
       "2         Nmeanings_Wordsmyth\n",
       "3          Nmeanings_Websters\n",
       "4                   NFeatures\n",
       "5                       Sem_N\n",
       "6         Assoc_Freq_Token123\n",
       "7                 Cue_SetSize\n",
       "8           LexicalD_RT_V_ELP\n",
       "9           LexicalD_RT_V_ECP\n",
       "10          LexicalD_RT_V_BLP\n",
       "11         LexicalD_RT_A_MALD\n",
       "12         LexicalD_RT_A_AELP\n",
       "13              Naming_RT_ELP\n",
       "14       SemanticD_RT_Calgary\n",
       "15                  rt_khanna\n",
       "16                     rt_ley\n",
       "17               rt_chiarello\n",
       "18                    rt_chen\n",
       "19             aoa_rt_cortese\n",
       "20    imageability_rt_cortese\n",
       "21                  rt_schock\n",
       "Name: norm, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "min_ord, max_ord = -5, 5\n",
    "alphas = np.logspace(\n",
    "    min_ord, max_ord, max_ord - min_ord + 1\n",
    ")\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for embed_name in tqdm(embeds.keys()):\n",
    "    embed = embeds[embed_name]\n",
    "    \n",
    "    to_print = []\n",
    "    for norm_name in tqdm(norms.columns, desc=embed_name):\n",
    "        \n",
    "        # Aligning data\n",
    "        y = norms[norm_name].dropna()\n",
    "        X, y = embed.align(y, axis=0, join='inner', copy=True) \n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = norm_metadata.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators\n",
    "        if norm_dtype in ['binary', 'multiclass']:\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(X, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv),\n",
    "                solver=solver, n_jobs=8\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "  \n",
    "        # Cross validation\n",
    "        associated_embed = norm_metadata.loc[norm_name, 'associated_embed']\n",
    "        check = checker(embed_name, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs) # stratification is automatically used for classification\n",
    "            r2s, mses = scores['test_r2'], - scores['test_neg_mse']\n",
    "            r2_mean, r2_sd = r2s.mean(), r2s.std()\n",
    "            mse_mean, mse_sd = mses.mean(), mses.std()\n",
    "        else:\n",
    "            r2_mean, r2_sd = np.nan, np.nan\n",
    "            mse_mean, mse_sd = np.nan, np.nan\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(X))\n",
    "        test_n = len(X) - train_n\n",
    "        p = X.shape[1]\n",
    "        embed_type = embed_to_type[embed_name]\n",
    "        rca.append([\n",
    "            embed_name, embed_type, norm_name, train_n, test_n, p, \n",
    "            r2_mean, r2_sd, mse_mean, mse_sd, check\n",
    "        ])\n",
    "        \n",
    "        to_print.append([norm_name, train_n, r2_mean, r2_sd, check])\n",
    "\n",
    "    to_print = pd.DataFrame(to_print, columns=['norm' , 'train_n', 'r2_mean', 'r2_sd', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10))\n",
    "\n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'embed_type', 'norm', 'train_n', 'test_n', 'p', \n",
    "        'r2_mean', 'r2_sd', 'mse_mean', 'mse_sd', 'check'\n",
    "    ]\n",
    ")\n",
    "\n",
    "rca.to_csv('../../data/results/rca.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
