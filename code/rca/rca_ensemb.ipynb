{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from rca import process_categorical, best_logistic_solver, k_fold_cross_val, make_binary_scoring, make_multiclass_scoring, checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:25.759027Z",
     "start_time": "2024-09-16T09:54:25.754838Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rca = pd.read_csv('../../data/final/rca.csv')\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.092158Z",
     "start_time": "2024-09-16T09:54:27.070861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                embed embed_type                     norm  train_n  test_n  \\\n",
       "0     CBOW_GoogleNews       text                 Freq_HAL    28012    7003   \n",
       "1     CBOW_GoogleNews       text                  Freq_KF    19285    4822   \n",
       "2     CBOW_GoogleNews       text           Freq_SUBTLEXUS    28636    7159   \n",
       "3     CBOW_GoogleNews       text           Freq_SUBTLEXUK    29316    7330   \n",
       "4     CBOW_GoogleNews       text                Freq_Blog    31876    7969   \n",
       "...               ...        ...                      ...      ...     ...   \n",
       "7295           THINGS   behavior   familiarity_vanarsdall      376      95   \n",
       "7296           THINGS   behavior  imageability_vanarsdall      376      95   \n",
       "7297           THINGS   behavior         familiarity_fear      173      44   \n",
       "7298           THINGS   behavior                 aoa_fear      173      44   \n",
       "7299           THINGS   behavior        imageability_fear      173      44   \n",
       "\n",
       "        p   r2_mean     r2_sd     mse_mean      mse_sd check  \n",
       "0     300  0.522106  0.008390     2.715519    0.072449  pass  \n",
       "1     300  0.500385  0.009733     0.156678    0.004765  pass  \n",
       "2     300  0.537246  0.009834     0.361360    0.007800  pass  \n",
       "3     300  0.545626  0.008433     0.446059    0.009071  pass  \n",
       "4     300  0.523688  0.008467     0.400176    0.009336  pass  \n",
       "...   ...       ...       ...          ...         ...   ...  \n",
       "7295   49  0.060692  0.083942  3326.617511  620.203961  pass  \n",
       "7296   49  0.053593  0.095680  1345.018025  292.430129  pass  \n",
       "7297   49  0.139160  0.160894     0.790788    0.216911  pass  \n",
       "7298   49 -0.021206  0.121789     0.533727    0.039008  pass  \n",
       "7299   49 -0.054670  0.126442     0.270169    0.051645  pass  \n",
       "\n",
       "[7300 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>norm</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>p</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_sd</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_sd</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_HAL</td>\n",
       "      <td>28012</td>\n",
       "      <td>7003</td>\n",
       "      <td>300</td>\n",
       "      <td>0.522106</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>2.715519</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_KF</td>\n",
       "      <td>19285</td>\n",
       "      <td>4822</td>\n",
       "      <td>300</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.156678</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUS</td>\n",
       "      <td>28636</td>\n",
       "      <td>7159</td>\n",
       "      <td>300</td>\n",
       "      <td>0.537246</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.361360</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUK</td>\n",
       "      <td>29316</td>\n",
       "      <td>7330</td>\n",
       "      <td>300</td>\n",
       "      <td>0.545626</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.446059</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_Blog</td>\n",
       "      <td>31876</td>\n",
       "      <td>7969</td>\n",
       "      <td>300</td>\n",
       "      <td>0.523688</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.400176</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>0.060692</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>3326.617511</td>\n",
       "      <td>620.203961</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>1345.018025</td>\n",
       "      <td>292.430129</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>0.139160</td>\n",
       "      <td>0.160894</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>0.216911</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>aoa_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.121789</td>\n",
       "      <td>0.533727</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.054670</td>\n",
       "      <td>0.126442</td>\n",
       "      <td>0.270169</td>\n",
       "      <td>0.051645</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7300 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "embed_means = rca.groupby('embed').mean(numeric_only=True)\n",
    "\n",
    "# Adding embed types\n",
    "with open('../../data/raw/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_means['type'] = embed_means.index.map(embed_to_type)\n",
    "\n",
    "# Finding top 2 text \n",
    "text_name_1, text_name_2 = (\n",
    "    embed_means.query('type == \"text\"').sort_values('r2_mean', ascending=False).head(2).index.tolist()\n",
    ")\n",
    "text_name_1, text_name_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.363397Z",
     "start_time": "2024-09-16T09:54:27.354472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CBOW_GoogleNews', 'morphoNLM')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.698454Z",
     "start_time": "2024-09-16T09:54:27.690651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding top behavior\n",
    "behavior_name = (\n",
    "    embed_means.query('type == \"behavior\"').sort_values('r2_mean', ascending=False).head(1).index[0]\n",
    ")\n",
    "behavior_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PPMI_SVD_SWOW'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading embeds\n",
    "text_1 = pd.read_csv(f'../../data/raw/embeds/{text_name_1}.csv', index_col=0)\n",
    "text_2 = pd.read_csv(f'../../data/raw/embeds/{text_name_2}.csv', index_col=0)\n",
    "behavior = pd.read_csv(f'../../data/raw/embeds/{behavior_name}.csv', index_col=0)\n",
    "\n",
    "# Aligning vocabs\n",
    "intersect = sorted(list(set.intersection(set(text_1.index), set(text_2.index), set(behavior.index))))\n",
    "text_1, text_2, behavior = text_1.loc[intersect], text_2.loc[intersect], behavior.loc[intersect]\n",
    "\n",
    "# Standardizing\n",
    "standardize = lambda df: (df - df.mean()) / df.std()\n",
    "text_1, text_2, behavior = standardize(text_1), standardize(text_2), standardize(behavior)\n",
    "\n",
    "# Ensembling for comparison\n",
    "embeds = {\n",
    "    text_name_1: text_1, \n",
    "    text_name_2: text_2,\n",
    "    text_name_1 + '&' + text_name_2: pd.concat([text_1, text_2], axis=1),\n",
    "    text_name_1 + '&' + behavior_name: pd.concat([text_1, behavior], axis=1),\n",
    "    text_name_2 + '&' + behavior_name: pd.concat([text_2, behavior], axis=1)\n",
    "}\n",
    "\n",
    "# Fixing column names\n",
    "for embed_name, embed in embeds.items():\n",
    "    embed.columns = list(range(embed.shape[1]))\n",
    "    embeds[embed_name] = embed\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:31.486298Z",
     "start_time": "2024-09-16T09:54:28.013607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBOW_GoogleNews': (11182, 300),\n",
       " 'morphoNLM': (11182, 50),\n",
       " 'CBOW_GoogleNews&morphoNLM': (11182, 350),\n",
       " 'CBOW_GoogleNews&PPMI_SVD_SWOW': (11182, 600),\n",
       " 'morphoNLM&PPMI_SVD_SWOW': (11182, 350)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "meta = pd.read_csv('../../data/raw/psychNorms_metadata.csv', index_col=0)\n",
    "meta['associated_embed'] = meta['associated_embed'].str.split(' ')\n",
    "\n",
    "norms = pd.read_csv('../../data/raw/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:33.389097Z",
     "start_time": "2024-09-16T09:54:31.487818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Freq_HAL  Freq_KF  Freq_SUBTLEXUS  Freq_SUBTLEXUK  Freq_Blog  \\\n",
       "'em               0.0      NaN             NaN             NaN        NaN   \n",
       "'neath            0.0      NaN             NaN             NaN        NaN   \n",
       "'re               0.0      NaN             NaN             NaN        NaN   \n",
       "'shun             0.0      NaN             NaN             NaN        NaN   \n",
       "'tis              0.0      NaN             NaN             NaN        NaN   \n",
       "...               ...      ...             ...             ...        ...   \n",
       "shrick            NaN      NaN             NaN             NaN        NaN   \n",
       "post office       NaN      NaN             NaN             NaN        NaN   \n",
       "fishing rod       NaN      NaN             NaN             NaN        NaN   \n",
       "March             NaN      NaN             NaN             NaN        NaN   \n",
       "May               NaN      NaN             NaN             NaN        NaN   \n",
       "\n",
       "             Freq_Twitter  Freq_News  Freq_CobW  Freq_CobS  CD_SUBTLEXUS  ...  \\\n",
       "'em                   NaN        NaN     1.3617     1.9138           NaN  ...   \n",
       "'neath                NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'re                   NaN        NaN     0.9031     1.6335           NaN  ...   \n",
       "'shun                 NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'tis                  NaN        NaN     0.4771     0.6021           NaN  ...   \n",
       "...                   ...        ...        ...        ...           ...  ...   \n",
       "shrick                NaN        NaN        NaN        NaN           NaN  ...   \n",
       "post office           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "fishing rod           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "March                 NaN        NaN        NaN        NaN           NaN  ...   \n",
       "May                   NaN        NaN        NaN        NaN           NaN  ...   \n",
       "\n",
       "             reproduction_vanarsdall  person_vanarsdall  goals_vanarsdall  \\\n",
       "'em                              NaN                NaN               NaN   \n",
       "'neath                           NaN                NaN               NaN   \n",
       "'re                              NaN                NaN               NaN   \n",
       "'shun                            NaN                NaN               NaN   \n",
       "'tis                             NaN                NaN               NaN   \n",
       "...                              ...                ...               ...   \n",
       "shrick                           NaN                NaN               NaN   \n",
       "post office                      NaN                NaN               NaN   \n",
       "fishing rod                      NaN                NaN               NaN   \n",
       "March                            NaN                NaN               NaN   \n",
       "May                              NaN                NaN               NaN   \n",
       "\n",
       "             movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "'em                          NaN                      NaN   \n",
       "'neath                       NaN                      NaN   \n",
       "'re                          NaN                      NaN   \n",
       "'shun                        NaN                      NaN   \n",
       "'tis                         NaN                      NaN   \n",
       "...                          ...                      ...   \n",
       "shrick                       NaN                      NaN   \n",
       "post office                  NaN                      NaN   \n",
       "fishing rod                  NaN                      NaN   \n",
       "March                        NaN                      NaN   \n",
       "May                          NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \n",
       "'em                       NaN       NaN                NaN  \n",
       "'neath                    NaN       NaN                NaN  \n",
       "'re                       NaN       NaN                NaN  \n",
       "'shun                     NaN       NaN                NaN  \n",
       "'tis                      NaN       NaN                NaN  \n",
       "...                       ...       ...                ...  \n",
       "shrick                   2.62      4.38               2.93  \n",
       "post office              3.79      3.07               5.29  \n",
       "fishing rod              2.29      3.38               5.64  \n",
       "March                    3.43      2.76               3.50  \n",
       "May                      4.10      2.86               2.79  \n",
       "\n",
       "[107085 rows x 292 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Freq_KF</th>\n",
       "      <th>Freq_SUBTLEXUS</th>\n",
       "      <th>Freq_SUBTLEXUK</th>\n",
       "      <th>Freq_Blog</th>\n",
       "      <th>Freq_Twitter</th>\n",
       "      <th>Freq_News</th>\n",
       "      <th>Freq_CobW</th>\n",
       "      <th>Freq_CobS</th>\n",
       "      <th>CD_SUBTLEXUS</th>\n",
       "      <th>...</th>\n",
       "      <th>reproduction_vanarsdall</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows × 292 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:33.991340Z",
     "start_time": "2024-09-16T09:54:33.389952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Log transforming selected norms\n",
    "with open('../../data/processed/norms_to_log.pkl', 'rb') as f:\n",
    "    norms_to_log = pickle.load(f)\n",
    "    norms[norms_to_log] = norms[norms_to_log].apply(np.log1p)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "min_alpha, max_alpha = -3, 6 \n",
    "alphas = np.logspace(min_alpha, max_alpha,  max_alpha - min_alpha + 1)\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 6\n",
    "\n",
    "solo_embed_names = [text_name_1, text_name_2, behavior_name] # For checking data leakage in checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:37.069691Z",
     "start_time": "2024-09-16T09:54:37.063180Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for norm_name in tqdm(norms.columns):\n",
    "    print(f'{norm_name}:')\n",
    "    y = norms[norm_name].dropna()\n",
    "    \n",
    "    to_print = []\n",
    "    for embed_name, embed in embeds.items():\n",
    "        \n",
    "        # Aligning embed with norm\n",
    "        X, y = embed.align(y, axis='index', join='inner', copy=True)\n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators ir categorical or continuous\n",
    "        if norm_dtype in ['binary', 'multiclass']: # categorical\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(y, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv), solver=solver\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "            \n",
    "        # Cross validation\n",
    "        associated_embed = meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(solo_embed_names, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs)\n",
    "            r2s, mses = scores['test_r2'], - scores['test_neg_mse']\n",
    "        else:\n",
    "            r2s, mses = pd.Series([np.nan] * outer_cv), pd.Series([np.nan] * outer_cv)\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(y))\n",
    "        for i, (r2, mse) in enumerate(zip(r2s, mses)):\n",
    "            rca.append([embed_name, norm_name, train_n, i + 1, r2, mse, check])\n",
    "            \n",
    "        # Printing\n",
    "        to_print.append([embed_name, r2s.mean(), r2s.std(), check])\n",
    "    to_print = pd.DataFrame(to_print, columns=['embed', 'r2_mean', 'r2_std', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10).reset_index(drop=True))\n",
    "    print('--------------------------------')\n",
    " \n",
    " \n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'norm', 'train_n', 'fold', 'r2', 'mse', 'check']\n",
    ")\n",
    "rca.to_csv('../../data/final/rca_ensemb.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-16T09:54:37.835988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c070304a40dd4b65b8e2420a37172b4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq_HAL:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.734332  0.014650  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.722789  0.014559  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.693546  0.017359  pass\n",
      "3                CBOW_GoogleNews  0.668775  0.011807  pass\n",
      "4                      morphoNLM  0.500359  0.041678  pass\n",
      "--------------------------------\n",
      "Freq_KF:\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
