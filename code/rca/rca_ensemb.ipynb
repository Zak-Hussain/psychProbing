{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "To do:\n",
    "1. double check logstic convergence issues\n",
    "2. need to re-run rca before running this since top mods are wrong "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import json\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:32:53.767363Z",
     "start_time": "2024-07-03T13:32:52.488735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rca = pd.read_csv('../../data/final/rca.csv')\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:33:00.649563Z",
     "start_time": "2024-07-03T13:33:00.618019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      embed                     norm  train_n    p        r2  \\\n",
       "0               SVD_sim_rel                 Freq_HAL     4506  300  0.089362   \n",
       "1               SVD_sim_rel                  Freq_KF     3776  300  0.036674   \n",
       "2               SVD_sim_rel           Freq_SUBTLEXUS     4450  300  0.156546   \n",
       "3               SVD_sim_rel           Freq_SUBTLEXUK     4472  300  0.060241   \n",
       "4               SVD_sim_rel                Freq_Blog     4652  300  0.098733   \n",
       "...                     ...                      ...      ...  ...       ...   \n",
       "7301  SGSoftMaxDecoder_SWOW         goals_vanarsdall      959  300  0.403416   \n",
       "7302  SGSoftMaxDecoder_SWOW      movement_vanarsdall      959  300  0.345155   \n",
       "7303  SGSoftMaxDecoder_SWOW  concreteness_vanarsdall      959  300  0.132158   \n",
       "7304  SGSoftMaxDecoder_SWOW   familiarity_vanarsdall      959  300  0.081765   \n",
       "7305  SGSoftMaxDecoder_SWOW  imageability_vanarsdall      959  300  0.198645   \n",
       "\n",
       "     check  \n",
       "0     pass  \n",
       "1     pass  \n",
       "2     pass  \n",
       "3     pass  \n",
       "4     pass  \n",
       "...    ...  \n",
       "7301  pass  \n",
       "7302  pass  \n",
       "7303  pass  \n",
       "7304  pass  \n",
       "7305  pass  \n",
       "\n",
       "[7306 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed</th>\n",
       "      <th>norm</th>\n",
       "      <th>train_n</th>\n",
       "      <th>p</th>\n",
       "      <th>r2</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVD_sim_rel</td>\n",
       "      <td>Freq_HAL</td>\n",
       "      <td>4506</td>\n",
       "      <td>300</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVD_sim_rel</td>\n",
       "      <td>Freq_KF</td>\n",
       "      <td>3776</td>\n",
       "      <td>300</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD_sim_rel</td>\n",
       "      <td>Freq_SUBTLEXUS</td>\n",
       "      <td>4450</td>\n",
       "      <td>300</td>\n",
       "      <td>0.156546</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD_sim_rel</td>\n",
       "      <td>Freq_SUBTLEXUK</td>\n",
       "      <td>4472</td>\n",
       "      <td>300</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVD_sim_rel</td>\n",
       "      <td>Freq_Blog</td>\n",
       "      <td>4652</td>\n",
       "      <td>300</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>SGSoftMaxDecoder_SWOW</td>\n",
       "      <td>goals_vanarsdall</td>\n",
       "      <td>959</td>\n",
       "      <td>300</td>\n",
       "      <td>0.403416</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>SGSoftMaxDecoder_SWOW</td>\n",
       "      <td>movement_vanarsdall</td>\n",
       "      <td>959</td>\n",
       "      <td>300</td>\n",
       "      <td>0.345155</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>SGSoftMaxDecoder_SWOW</td>\n",
       "      <td>concreteness_vanarsdall</td>\n",
       "      <td>959</td>\n",
       "      <td>300</td>\n",
       "      <td>0.132158</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>SGSoftMaxDecoder_SWOW</td>\n",
       "      <td>familiarity_vanarsdall</td>\n",
       "      <td>959</td>\n",
       "      <td>300</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305</th>\n",
       "      <td>SGSoftMaxDecoder_SWOW</td>\n",
       "      <td>imageability_vanarsdall</td>\n",
       "      <td>959</td>\n",
       "      <td>300</td>\n",
       "      <td>0.198645</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7306 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "embed_means = rca.groupby('embed').mean(numeric_only=True)\n",
    "\n",
    "# Adding embed types\n",
    "with open('../../data/final/dtype_to_embed.json', 'r') as f:\n",
    "    type_2_embed = json.load(f)\n",
    "embed_2_type = lambda name: 'text' if name in type_2_embed['text'] else 'behavior' if name in type_2_embed['behavior'] else 'brain'\n",
    "embed_means['type'] = embed_means.index.map(embed_2_type)\n",
    "\n",
    "top_n = 2\n",
    "\n",
    "# ensembling top text\n",
    "top_text_names = embed_means.query('type == \"text\"').sort_values('r2', ascending=False).head(top_n).index.tolist()\n",
    "text_text_names = list(itertools.combinations(top_text_names, r=2))\n",
    "text_text_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:33:01.943557Z",
     "start_time": "2024-07-03T13:33:01.920659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fastText_CommonCrawl', 'GloVe_CommonCrawl')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:33:03.034020Z",
     "start_time": "2024-07-03T13:33:03.025271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensembling top behavior\n",
    "top_behavior_names = embed_means.query('type == \"behavior\"').sort_values('r2', ascending=False).head(top_n).index.tolist()\n",
    "text_behavior_names =  []\n",
    "for text_name in top_text_names:\n",
    "    for behavior_name in top_behavior_names:\n",
    "        text_behavior_names.append((text_name, behavior_name))\n",
    "text_behavior_names"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fastText_CommonCrawl', 'PPMI_SVD_SWOW'),\n",
       " ('fastText_CommonCrawl', 'norms_sensorimotor'),\n",
       " ('GloVe_CommonCrawl', 'PPMI_SVD_SWOW'),\n",
       " ('GloVe_CommonCrawl', 'norms_sensorimotor')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "standarize = lambda df: (df - df.mean()) / df.std()\n",
    "\n",
    "# Loading embeddings\n",
    "embeds = {}\n",
    "for name in top_text_names + top_behavior_names:\n",
    "    embeds[name] = pd.read_pickle(f'../../data/processed/pulled_embeds/{name}.pkl')\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:33:04.193083Z",
     "start_time": "2024-07-03T13:33:04.033067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fastText_CommonCrawl': (88953, 300),\n",
       " 'GloVe_CommonCrawl': (88408, 300),\n",
       " 'PPMI_SVD_SWOW': (11781, 300),\n",
       " 'norms_sensorimotor': (36851, 11)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "meta = pd.read_csv('../../data/final/norm_metadata.csv', index_col=0)\n",
    "meta['associated_embed'] = meta['associated_embed'].str.split(' ')\n",
    "\n",
    "norms = pd.read_csv('../../data/final/norms.csv', index_col=0)\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:33:07.888069Z",
     "start_time": "2024-07-03T13:33:06.773240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/5gbrfvhn687dxwjl5_xg21t40000gq/T/ipykernel_50490/1726302198.py:4: DtypeWarning: Columns (22,23,170) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  norms = pd.read_csv('../../data/final/norms.csv', index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               Freq_HAL  Freq_KF  Freq_SUBTLEXUS  Freq_SUBTLEXUK  Freq_Blog  \\\n",
       "'em                 0.0      NaN             NaN             NaN        NaN   \n",
       "'neath              0.0      NaN             NaN             NaN        NaN   \n",
       "'re                 0.0      NaN             NaN             NaN        NaN   \n",
       "'shun               0.0      NaN             NaN             NaN        NaN   \n",
       "'tis                0.0      NaN             NaN             NaN        NaN   \n",
       "...                 ...      ...             ...             ...        ...   \n",
       "trappy              NaN      NaN             NaN             NaN        NaN   \n",
       "vocalise            NaN      NaN             NaN             NaN        NaN   \n",
       "listened..to.       NaN      NaN             NaN             NaN        NaN   \n",
       "spoke..to.          NaN      NaN             NaN             NaN        NaN   \n",
       "used.1              NaN      NaN             NaN             NaN        NaN   \n",
       "\n",
       "               Freq_Twitter  Freq_News  Freq_CobW  Freq_CobS  CD_SUBTLEXUS  \\\n",
       "'em                     NaN        NaN     1.3617     1.9138           NaN   \n",
       "'neath                  NaN        NaN     0.0000     0.0000           NaN   \n",
       "'re                     NaN        NaN     0.9031     1.6335           NaN   \n",
       "'shun                   NaN        NaN     0.0000     0.0000           NaN   \n",
       "'tis                    NaN        NaN     0.4771     0.6021           NaN   \n",
       "...                     ...        ...        ...        ...           ...   \n",
       "trappy                  NaN        NaN        NaN        NaN           NaN   \n",
       "vocalise                NaN        NaN        NaN        NaN           NaN   \n",
       "listened..to.           NaN        NaN        NaN        NaN           NaN   \n",
       "spoke..to.              NaN        NaN        NaN        NaN           NaN   \n",
       "used.1                  NaN        NaN        NaN        NaN           NaN   \n",
       "\n",
       "               ...  iconicity_winter_2017  living_vanarsdall  \\\n",
       "'em            ...                    NaN                NaN   \n",
       "'neath         ...                    NaN                NaN   \n",
       "'re            ...                    NaN                NaN   \n",
       "'shun          ...                    NaN                NaN   \n",
       "'tis           ...                    NaN                NaN   \n",
       "...            ...                    ...                ...   \n",
       "trappy         ...                    NaN                NaN   \n",
       "vocalise       ...                    NaN                NaN   \n",
       "listened..to.  ...                    NaN                NaN   \n",
       "spoke..to.     ...                    NaN                NaN   \n",
       "used.1         ...                    NaN                NaN   \n",
       "\n",
       "               thought_vanarsdall  reproduction_vanarsdall  person_vanarsdall  \\\n",
       "'em                           NaN                      NaN                NaN   \n",
       "'neath                        NaN                      NaN                NaN   \n",
       "'re                           NaN                      NaN                NaN   \n",
       "'shun                         NaN                      NaN                NaN   \n",
       "'tis                          NaN                      NaN                NaN   \n",
       "...                           ...                      ...                ...   \n",
       "trappy                        NaN                      NaN                NaN   \n",
       "vocalise                      NaN                      NaN                NaN   \n",
       "listened..to.                 NaN                      NaN                NaN   \n",
       "spoke..to.                    NaN                      NaN                NaN   \n",
       "used.1                        NaN                      NaN                NaN   \n",
       "\n",
       "               goals_vanarsdall  movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "'em                         NaN                  NaN                      NaN   \n",
       "'neath                      NaN                  NaN                      NaN   \n",
       "'re                         NaN                  NaN                      NaN   \n",
       "'shun                       NaN                  NaN                      NaN   \n",
       "'tis                        NaN                  NaN                      NaN   \n",
       "...                         ...                  ...                      ...   \n",
       "trappy                      NaN                  NaN                      NaN   \n",
       "vocalise                    NaN                  NaN                      NaN   \n",
       "listened..to.               NaN                  NaN                      NaN   \n",
       "spoke..to.                  NaN                  NaN                      NaN   \n",
       "used.1                      NaN                  NaN                      NaN   \n",
       "\n",
       "               familiarity_vanarsdall  imageability_vanarsdall  \n",
       "'em                               NaN                      NaN  \n",
       "'neath                            NaN                      NaN  \n",
       "'re                               NaN                      NaN  \n",
       "'shun                             NaN                      NaN  \n",
       "'tis                              NaN                      NaN  \n",
       "...                               ...                      ...  \n",
       "trappy                            NaN                      NaN  \n",
       "vocalise                          NaN                      NaN  \n",
       "listened..to.                     NaN                      NaN  \n",
       "spoke..to.                        NaN                      NaN  \n",
       "used.1                            NaN                      NaN  \n",
       "\n",
       "[108959 rows x 281 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Freq_KF</th>\n",
       "      <th>Freq_SUBTLEXUS</th>\n",
       "      <th>Freq_SUBTLEXUK</th>\n",
       "      <th>Freq_Blog</th>\n",
       "      <th>Freq_Twitter</th>\n",
       "      <th>Freq_News</th>\n",
       "      <th>Freq_CobW</th>\n",
       "      <th>Freq_CobS</th>\n",
       "      <th>CD_SUBTLEXUS</th>\n",
       "      <th>...</th>\n",
       "      <th>iconicity_winter_2017</th>\n",
       "      <th>living_vanarsdall</th>\n",
       "      <th>thought_vanarsdall</th>\n",
       "      <th>reproduction_vanarsdall</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trappy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocalise</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listened..to.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoke..to.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used.1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108959 rows × 281 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "standardize = lambda df: (df - df.mean()) / df.std()\n",
    "\n",
    "def mcfadden_r2_binary(y_true, y_pred_proba):\n",
    "    # Compute the log-likelihood of the model\n",
    "    ll_model = -log_loss(y_true, y_pred_proba, normalize=False)\n",
    "\n",
    "    # Compute the log-likelihood of the null model (predicting the mean)\n",
    "    probas_null = np.full_like(y_pred_proba, fill_value=y_true.mean(), dtype=np.float64)\n",
    "    ll_null = -log_loss(y_true, probas_null, normalize=False)\n",
    "\n",
    "    # Calculate McFadden's R2\n",
    "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
    "    return pseudo_r2\n",
    "\n",
    "def mcfadden_r2_multiclass(y_true, y_pred_proba):\n",
    "    # Convert y_true to a binary matrix representation (one-hot encoding)\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_binary = lb.fit_transform(y_true)\n",
    "\n",
    "    # Compute the log-likelihood of the model\n",
    "    ll_model = -log_loss(y_true_binary, y_pred_proba, normalize=False)\n",
    "\n",
    "    # Compute the log-likelihood of the null model (predicting class proportions)\n",
    "    class_proportions = y_true_binary.mean(axis=0)\n",
    "    probas_null = np.array([class_proportions] * len(y_true))\n",
    "    ll_null = -log_loss(y_true_binary, probas_null, normalize=False)\n",
    "\n",
    "    # Calculate McFadden's R2\n",
    "    pseudo_r2 = 1 - (ll_model / ll_null)\n",
    "    return pseudo_r2\n",
    "\n",
    "def best_logistic_solver(y, dtype):\n",
    "    \"\"\"\n",
    "    Pick the fastest 'l2'-compatible for LogisticCV the given data based on a few heuristics.\n",
    "    \"\"\"\n",
    "    if len(y) < 1000:  # Arbitrary threshold for \"small\" datasets\n",
    "        if dtype == 'binary':\n",
    "            return 'liblinear'\n",
    "        else:\n",
    "            return 'lbfgs'\n",
    "    else:\n",
    "        return 'saga' \n",
    "\n",
    "def process_categorical(X_1, X_2, y):\n",
    "    \"\"\"Removes classes with too few observations\"\"\"\n",
    "    min_class_n = outer_cv * inner_cv\n",
    "    classes_to_keep = y.value_counts()[y.value_counts() >= min_class_n].index\n",
    "    to_keep_bool = y.isin(classes_to_keep)\n",
    "    X_1, X_2, y = X_1.loc[to_keep_bool], X_2.loc[to_keep_bool], y.loc[to_keep_bool]\n",
    "    return X_1, X_2, y\n",
    "\n",
    "def check_data(X_names, y_name, y, dtype):\n",
    "    associated_embeds = meta.loc[y_name, 'associated_embed']\n",
    "    if isinstance(associated_embeds, list):\n",
    "        if set(X_names) & set(associated_embeds):  # if either is associated\n",
    "            return 'associated_embed'\n",
    "    elif (1 - (1 / outer_cv)) * len(y) < 600:  # ensures n>p \n",
    "        return 'too few observations'  \n",
    "    elif (dtype != 'continuous') and (len(y.unique()) < 2):\n",
    "        return 'too few classes (of sufficient size)'\n",
    "    else:\n",
    "        return 'pass'\n",
    "    \n",
    "def top_or_bottom(best, possibles):\n",
    "    if isinstance(best, float):\n",
    "        if best == possibles[0]:\n",
    "            return 'bottom'\n",
    "        elif best == possibles[-1]:\n",
    "            return 'top'\n",
    "        else:\n",
    "            return 'pass'\n",
    "    else:\n",
    "        for b in best:\n",
    "            result = top_or_bottom(b, possibles)\n",
    "            if result != 'pass':\n",
    "                return result\n",
    "        return 'pass'\n",
    "\n",
    "def check_penalty(estim, X, y, dtype):\n",
    "    \"\"\"Checks that none of the best penalties are at either extreme of alphas or Cs\"\"\" \n",
    "    stratify = y if dtype != 'continuous' else None\n",
    "    train_size = 1 - (1 / outer_cv)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, shuffle=True, stratify=stratify\n",
    "    )\n",
    "    estim.fit(X_train, y_train)\n",
    "                      \n",
    "    if dtype == 'continuous':\n",
    "        result = top_or_bottom(estim.alpha_, alphas)\n",
    "    else:\n",
    "        result = top_or_bottom(estim.C_, Cs)\n",
    "    \n",
    "    if result != 'pass':\n",
    "        print(f'Penalty at {result} of range')\n",
    "        return result\n",
    "\n",
    "\n",
    "def cross_val(estim, X, y, dtype):\n",
    "    if dtype == 'continuous':\n",
    "        return cross_val_score(estim, X, y, cv=outer_cv, n_jobs=n_jobs, scoring='r2')\n",
    "    elif dtype == 'binary':\n",
    "        return cross_val_score(estim, X, y, cv=outer_cv, n_jobs=n_jobs, scoring=binary_scorer)\n",
    "    else:\n",
    "        return cross_val_score(estim, X, y, cv=outer_cv, n_jobs=n_jobs, scoring=multiclass_scorer)\n",
    "\n",
    "\n",
    "# Ridge\n",
    "min_alpha, max_alpha = -3, 6 \n",
    "alphas = np.logspace(-3, 6,  max_alpha - min_alpha + 1)\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scorer = make_scorer(mcfadden_r2_binary, needs_proba=True, greater_is_better=True)\n",
    "multiclass_scorer = make_scorer(mcfadden_r2_multiclass, needs_proba=True, greater_is_better=True)\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:35:31.688446Z",
     "start_time": "2024-07-03T13:35:31.672337Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for (text_name, behavior_name) in text_behavior_names:\n",
    "    \n",
    "    # Loading text-text baseline embedding\n",
    "    text_text_embed = pd.concat([embeds[name] for name in top_text_names], axis=1, join='inner')\n",
    "    text_text_embed.columns = list(range(text_text_embed.shape[1]))\n",
    "    text_text_name = '&'.join(top_text_names)\n",
    "\n",
    "    # Loading text-behavior embedding\n",
    "    text_behavior_embed = pd.concat([embeds[text_name], embeds[behavior_name]], axis=1, join='inner')\n",
    "    text_behavior_embed.columns = list(range(text_behavior_embed.shape[1]))\n",
    "    text_behavior_name = f'{text_name}&{behavior_name}'\n",
    "    \n",
    "    # Aligning embedding to have same vocab for fair comparison\n",
    "    text_text_embed, text_behavior_embed = text_text_embed.align(text_behavior_embed, axis='index', join='inner')\n",
    "    \n",
    "    # Standardizing\n",
    "    text_text_embed, text_behavior_embed = standardize(text_text_embed), standardize(text_behavior_embed)\n",
    "       \n",
    "    for norm_name in tqdm(norms.columns, desc=text_behavior_name):\n",
    "        \n",
    "        # Aligning embeddings with norm\n",
    "        norm = norms[norm_name].dropna()\n",
    "        tt_embed, norm = text_text_embed.align(norm, axis='index', join='inner')\n",
    "        tb_embed, norm = text_behavior_embed.align(norm, axis='index', join='inner')\n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators ir categorical or continuous\n",
    "        if norm_dtype in ['binary', 'multiclass']: # categorical\n",
    "            tt_embed, tb_embed, norm = process_categorical(tt_embed, tb_embed, norm)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(norm.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(norm, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv), solver=solver\n",
    "            )\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, 'r2'\n",
    "            \n",
    "        # Cross validation\n",
    "        embed_names = top_text_names + [behavior_name]\n",
    "        data_check = check_data(embed_names, norm_name, norm, norm_dtype)\n",
    "        if data_check == 'pass':\n",
    "            penalty_check = check_penalty(estimator, tb_embed, norm, norm_dtype)\n",
    "            text_text_scores = cross_val(estimator, tt_embed, norm, norm_dtype)\n",
    "            text_behavior_scores = cross_val(estimator, tb_embed, norm, norm_dtype)\n",
    "        else:\n",
    "            text_text_scores, text_behavior_scores = [np.nan] * outer_cv, [np.nan] * outer_cv\n",
    "            penalty_check = [np.nan]*outer_cv\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(norm))\n",
    "        for text_score, text_behavior_score in zip(text_text_scores, text_behavior_scores):\n",
    "            rca.append([\n",
    "                text_text_name, text_behavior_name, norm_name, train_n, text_score, \n",
    "                text_behavior_score, data_check, penalty_check\n",
    "            ])\n",
    " \n",
    " \n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=['text_text_name', 'text_behavior_name', 'norm', 'train_n', 'r2_text',  'r2_ensemb', 'data_check', 'penalty_check']\n",
    ")\n",
    "# rca.to_csv('../../data/final/rca_ensemb.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:37:55.571217Z",
     "start_time": "2024-07-03T13:35:31.766001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastText_CommonCrawl&PPMI_SVD_SWOW:   0%|          | 0/281 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1ff4b482f804f0e8115f4cabe6efc92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhussain/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/zhussain/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 52\u001B[0m\n\u001B[1;32m     50\u001B[0m data_check \u001B[38;5;241m=\u001B[39m check_data(embed_names, norm_name, norm, norm_dtype)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_check \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 52\u001B[0m     penalty_check \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_penalty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_embed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m     text_text_scores \u001B[38;5;241m=\u001B[39m cross_val(estimator, tt_embed, norm, norm_dtype)\n\u001B[1;32m     54\u001B[0m     text_behavior_scores \u001B[38;5;241m=\u001B[39m cross_val(estimator, tb_embed, norm, norm_dtype)\n",
      "Cell \u001B[0;32mIn[9], line 87\u001B[0m, in \u001B[0;36mcheck_penalty\u001B[0;34m(estim, X, y, dtype)\u001B[0m\n\u001B[1;32m     82\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m outer_cv)\n\u001B[1;32m     84\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\n\u001B[1;32m     85\u001B[0m     X, y, train_size\u001B[38;5;241m=\u001B[39mtrain_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, stratify\u001B[38;5;241m=\u001B[39mstratify\n\u001B[1;32m     86\u001B[0m )\n\u001B[0;32m---> 87\u001B[0m \u001B[43mestim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontinuous\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     90\u001B[0m     result \u001B[38;5;241m=\u001B[39m top_or_bottom(estim\u001B[38;5;241m.\u001B[39malpha_, alphas)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1869\u001B[0m, in \u001B[0;36mLogisticRegressionCV.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1866\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1867\u001B[0m     prefer \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocesses\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1869\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1870\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1871\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1872\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1873\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1874\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1875\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1876\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1877\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1878\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1879\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdual\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1880\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintercept_scaling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintercept_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1891\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1892\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1893\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miter_encoded_labels\u001B[49m\n\u001B[1;32m   1894\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfolds\u001B[49m\n\u001B[1;32m   1895\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ml1_ratios_\u001B[49m\n\u001B[1;32m   1896\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1898\u001B[0m \u001B[38;5;66;03m# _log_reg_scoring_path will output different shapes depending on the\u001B[39;00m\n\u001B[1;32m   1899\u001B[0m \u001B[38;5;66;03m# multi_class param, so we need to reshape the outputs accordingly.\u001B[39;00m\n\u001B[1;32m   1900\u001B[0m \u001B[38;5;66;03m# Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1907\u001B[0m \u001B[38;5;66;03m#  (n_classes, n_folds, n_Cs . n_l1_ratios) or\u001B[39;00m\n\u001B[1;32m   1908\u001B[0m \u001B[38;5;66;03m#  (1, n_folds, n_Cs . n_l1_ratios)\u001B[39;00m\n\u001B[1;32m   1909\u001B[0m coefs_paths, Cs, scores, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:1048\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1040\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1045\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1046\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1048\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1049\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1051\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    781\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 782\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:723\u001B[0m, in \u001B[0;36m_log_reg_scoring_path\u001B[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001B[0m\n\u001B[1;32m    720\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n\u001B[1;32m    721\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight[train]\n\u001B[0;32m--> 723\u001B[0m coefs, Cs, n_iter \u001B[38;5;241m=\u001B[39m \u001B[43m_logistic_regression_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    725\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    726\u001B[0m \u001B[43m    \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    728\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    729\u001B[0m \u001B[43m    \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    731\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    732\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    733\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    734\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    735\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdual\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintercept_scaling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mintercept_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    742\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    743\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    745\u001B[0m log_reg \u001B[38;5;241m=\u001B[39m LogisticRegression(solver\u001B[38;5;241m=\u001B[39msolver, multi_class\u001B[38;5;241m=\u001B[39mmulti_class)\n\u001B[1;32m    747\u001B[0m \u001B[38;5;66;03m# The score method of Logistic Regression has a classes_ attribute.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:524\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[1;32m    521\u001B[0m         alpha \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m l1_ratio)\n\u001B[1;32m    522\u001B[0m         beta \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C) \u001B[38;5;241m*\u001B[39m l1_ratio\n\u001B[0;32m--> 524\u001B[0m     w0, n_iter_i, warm_start_sag \u001B[38;5;241m=\u001B[39m \u001B[43msag_solver\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarm_start_sag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_saga\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msolver\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msaga\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    543\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msolver must be one of \u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    544\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnewton-cg\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msag\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m}, got \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m solver\n\u001B[1;32m    545\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:325\u001B[0m, in \u001B[0;36msag_solver\u001B[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001B[0m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mZeroDivisionError\u001B[39;00m(\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrent sag implementation does not handle \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe case step_size * alpha_scaled == 1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[1;32m    324\u001B[0m sag \u001B[38;5;241m=\u001B[39m sag64 \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64 \u001B[38;5;28;01melse\u001B[39;00m sag32\n\u001B[0;32m--> 325\u001B[0m num_seen, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[43msag\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintercept_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43malpha_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta_scaled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43msum_gradient_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgradient_memory_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseen_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_seen_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintercept_sum_gradient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mintercept_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_saga\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_iter_ \u001B[38;5;241m==\u001B[39m max_iter:\n\u001B[1;32m    350\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    351\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    352\u001B[0m         ConvergenceWarning,\n\u001B[1;32m    353\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
