{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To do:\n",
    "1. fix scoring and checker code following function changes"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from rca import process_categorical, best_logistic_solver, k_fold_cross_val, make_binary_scoring, make_multiclass_scoring, checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:48.114882Z",
     "start_time": "2024-08-08T10:04:47.472713Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rca = pd.read_csv('../../data/final/rca.csv')\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:48.139455Z",
     "start_time": "2024-08-08T10:04:48.115808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                embed embed_type                     norm  train_n    p  \\\n",
       "0     CBOW_GoogleNews       text                 Freq_HAL    51174  300   \n",
       "1     CBOW_GoogleNews       text                  Freq_KF    26605  300   \n",
       "2     CBOW_GoogleNews       text           Freq_SUBTLEXUS    43939  300   \n",
       "3     CBOW_GoogleNews       text           Freq_SUBTLEXUK    47398  300   \n",
       "4     CBOW_GoogleNews       text                Freq_Blog    53251  300   \n",
       "...               ...        ...                      ...      ...  ...   \n",
       "7295           THINGS   behavior   familiarity_vanarsdall      376   49   \n",
       "7296           THINGS   behavior  imageability_vanarsdall      376   49   \n",
       "7297           THINGS   behavior         familiarity_fear      173   49   \n",
       "7298           THINGS   behavior                 aoa_fear      173   49   \n",
       "7299           THINGS   behavior        imageability_fear      173   49   \n",
       "\n",
       "       r2_mean     r2_sd check  \n",
       "0     0.422344  0.006255  pass  \n",
       "1     0.463358  0.009852  pass  \n",
       "2     0.488748  0.006706  pass  \n",
       "3     0.479608  0.008173  pass  \n",
       "4     0.463084  0.006165  pass  \n",
       "...        ...       ...   ...  \n",
       "7295  0.060692  0.083942  pass  \n",
       "7296  0.053593  0.095680  pass  \n",
       "7297  0.139160  0.160894  pass  \n",
       "7298 -0.021206  0.121789  pass  \n",
       "7299 -0.054670  0.126442  pass  \n",
       "\n",
       "[7300 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>norm</th>\n",
       "      <th>train_n</th>\n",
       "      <th>p</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_sd</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_HAL</td>\n",
       "      <td>51174</td>\n",
       "      <td>300</td>\n",
       "      <td>0.422344</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_KF</td>\n",
       "      <td>26605</td>\n",
       "      <td>300</td>\n",
       "      <td>0.463358</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUS</td>\n",
       "      <td>43939</td>\n",
       "      <td>300</td>\n",
       "      <td>0.488748</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUK</td>\n",
       "      <td>47398</td>\n",
       "      <td>300</td>\n",
       "      <td>0.479608</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_Blog</td>\n",
       "      <td>53251</td>\n",
       "      <td>300</td>\n",
       "      <td>0.463084</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>49</td>\n",
       "      <td>0.060692</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>49</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>49</td>\n",
       "      <td>0.139160</td>\n",
       "      <td>0.160894</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>aoa_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.121789</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.054670</td>\n",
       "      <td>0.126442</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7300 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "embed_means = rca.groupby('embed').mean(numeric_only=True)\n",
    "\n",
    "# Adding embed types\n",
    "with open('../../data/raw/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_means['type'] = embed_means.index.map(embed_to_type)\n",
    "\n",
    "# Finding top 2 text \n",
    "text_name_1, text_name_2 = (\n",
    "    embed_means.query('type == \"text\"').sort_values('r2_mean', ascending=False).head(2).index.tolist()\n",
    ")\n",
    "text_name_1, text_name_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:48.151618Z",
     "start_time": "2024-08-08T10:04:48.141389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CBOW_GoogleNews', 'morphoNLM')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:48.157243Z",
     "start_time": "2024-08-08T10:04:48.152742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding top behavior\n",
    "behavior_name = (\n",
    "    embed_means.query('type == \"behavior\"').sort_values('r2_mean', ascending=False).head(1).index[0]\n",
    ")\n",
    "behavior_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PPMI_SVD_SWOW'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading embeds\n",
    "text_1 = pd.read_csv(f'../../data/raw/embeds/{text_name_1}.csv', index_col=0)\n",
    "text_2 = pd.read_csv(f'../../data/raw/embeds/{text_name_2}.csv', index_col=0)\n",
    "behavior = pd.read_csv(f'../../data/raw/embeds/{behavior_name}.csv', index_col=0)\n",
    "\n",
    "# Aligning vocabs\n",
    "intersect = sorted(list(set.intersection(set(text_1.index), set(text_2.index), set(behavior.index))))\n",
    "text_1, text_2, behavior = text_1.loc[intersect], text_2.loc[intersect], behavior.loc[intersect]\n",
    "\n",
    "# Standardizing\n",
    "standardize = lambda df: (df - df.mean()) / df.std()\n",
    "text_1, text_2, behavior = standardize(text_1), standardize(text_2), standardize(behavior)\n",
    "\n",
    "# Ensembling for comparison\n",
    "embeds = {\n",
    "    text_name_1: text_1, \n",
    "    text_name_2: text_2,\n",
    "    text_name_1 + '&' + text_name_2: pd.concat([text_1, text_2], axis=1),\n",
    "    text_name_1 + '&' + behavior_name: pd.concat([text_1, behavior], axis=1),\n",
    "    text_name_2 + '&' + behavior_name: pd.concat([text_2, behavior], axis=1)\n",
    "}\n",
    "\n",
    "# Fixing column names\n",
    "for embed_name, embed in embeds.items():\n",
    "    embed.columns = list(range(embed.shape[1]))\n",
    "    embeds[embed_name] = embed\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:52.570742Z",
     "start_time": "2024-08-08T10:04:48.158395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBOW_GoogleNews': (11182, 300),\n",
       " 'morphoNLM': (11182, 50),\n",
       " 'CBOW_GoogleNews&morphoNLM': (11182, 350),\n",
       " 'CBOW_GoogleNews&PPMI_SVD_SWOW': (11182, 600),\n",
       " 'morphoNLM&PPMI_SVD_SWOW': (11182, 350)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "meta = pd.read_csv('../../data/raw/psychNorms_metadata.csv', index_col=0)\n",
    "meta['associated_embed'] = meta['associated_embed'].str.split(' ')\n",
    "\n",
    "norms = pd.read_csv('../../data/raw/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:54.471864Z",
     "start_time": "2024-08-08T10:04:52.571661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Freq_HAL  Freq_KF  Freq_SUBTLEXUS  Freq_SUBTLEXUK  Freq_Blog  \\\n",
       "'em               0.0      NaN             NaN             NaN        NaN   \n",
       "'neath            0.0      NaN             NaN             NaN        NaN   \n",
       "'re               0.0      NaN             NaN             NaN        NaN   \n",
       "'shun             0.0      NaN             NaN             NaN        NaN   \n",
       "'tis              0.0      NaN             NaN             NaN        NaN   \n",
       "...               ...      ...             ...             ...        ...   \n",
       "shrick            NaN      NaN             NaN             NaN        NaN   \n",
       "post office       NaN      NaN             NaN             NaN        NaN   \n",
       "fishing rod       NaN      NaN             NaN             NaN        NaN   \n",
       "March             NaN      NaN             NaN             NaN        NaN   \n",
       "May               NaN      NaN             NaN             NaN        NaN   \n",
       "\n",
       "             Freq_Twitter  Freq_News  Freq_CobW  Freq_CobS  CD_SUBTLEXUS  ...  \\\n",
       "'em                   NaN        NaN     1.3617     1.9138           NaN  ...   \n",
       "'neath                NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'re                   NaN        NaN     0.9031     1.6335           NaN  ...   \n",
       "'shun                 NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'tis                  NaN        NaN     0.4771     0.6021           NaN  ...   \n",
       "...                   ...        ...        ...        ...           ...  ...   \n",
       "shrick                NaN        NaN        NaN        NaN           NaN  ...   \n",
       "post office           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "fishing rod           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "March                 NaN        NaN        NaN        NaN           NaN  ...   \n",
       "May                   NaN        NaN        NaN        NaN           NaN  ...   \n",
       "\n",
       "             reproduction_vanarsdall  person_vanarsdall  goals_vanarsdall  \\\n",
       "'em                              NaN                NaN               NaN   \n",
       "'neath                           NaN                NaN               NaN   \n",
       "'re                              NaN                NaN               NaN   \n",
       "'shun                            NaN                NaN               NaN   \n",
       "'tis                             NaN                NaN               NaN   \n",
       "...                              ...                ...               ...   \n",
       "shrick                           NaN                NaN               NaN   \n",
       "post office                      NaN                NaN               NaN   \n",
       "fishing rod                      NaN                NaN               NaN   \n",
       "March                            NaN                NaN               NaN   \n",
       "May                              NaN                NaN               NaN   \n",
       "\n",
       "             movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "'em                          NaN                      NaN   \n",
       "'neath                       NaN                      NaN   \n",
       "'re                          NaN                      NaN   \n",
       "'shun                        NaN                      NaN   \n",
       "'tis                         NaN                      NaN   \n",
       "...                          ...                      ...   \n",
       "shrick                       NaN                      NaN   \n",
       "post office                  NaN                      NaN   \n",
       "fishing rod                  NaN                      NaN   \n",
       "March                        NaN                      NaN   \n",
       "May                          NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \n",
       "'em                       NaN       NaN                NaN  \n",
       "'neath                    NaN       NaN                NaN  \n",
       "'re                       NaN       NaN                NaN  \n",
       "'shun                     NaN       NaN                NaN  \n",
       "'tis                      NaN       NaN                NaN  \n",
       "...                       ...       ...                ...  \n",
       "shrick                   2.62      4.38               2.93  \n",
       "post office              3.79      3.07               5.29  \n",
       "fishing rod              2.29      3.38               5.64  \n",
       "March                    3.43      2.76               3.50  \n",
       "May                      4.10      2.86               2.79  \n",
       "\n",
       "[107085 rows x 292 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Freq_KF</th>\n",
       "      <th>Freq_SUBTLEXUS</th>\n",
       "      <th>Freq_SUBTLEXUK</th>\n",
       "      <th>Freq_Blog</th>\n",
       "      <th>Freq_Twitter</th>\n",
       "      <th>Freq_News</th>\n",
       "      <th>Freq_CobW</th>\n",
       "      <th>Freq_CobS</th>\n",
       "      <th>CD_SUBTLEXUS</th>\n",
       "      <th>...</th>\n",
       "      <th>reproduction_vanarsdall</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows × 292 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "min_alpha, max_alpha = -3, 6 \n",
    "alphas = np.logspace(min_alpha, max_alpha,  max_alpha - min_alpha + 1)\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 6\n",
    "\n",
    "solo_embed_names = [text_name_1, text_name_2, behavior_name] # For checking data leakage in checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:04:54.475796Z",
     "start_time": "2024-08-08T10:04:54.472662Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for norm_name in tqdm(norms.columns):\n",
    "    print(f'{norm_name}:')\n",
    "    y = norms[norm_name].dropna()\n",
    "    \n",
    "    to_print = []\n",
    "    for embed_name, embed in embeds.items():\n",
    "        \n",
    "        # Aligning embed with norm\n",
    "        X, y = embed.align(y, axis='index', join='inner', copy=True)\n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators ir categorical or continuous\n",
    "        if norm_dtype in ['binary', 'multiclass']: # categorical\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(y, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv), solver=solver\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, 'r2'\n",
    "            \n",
    "        # Cross validation\n",
    "        associated_embed = meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(solo_embed_names, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs)\n",
    "        else:\n",
    "            scores = pd.Series([np.nan] * outer_cv)\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(y))\n",
    "        for i, score in enumerate(scores):\n",
    "            rca.append([embed_name, norm_name, train_n, i + 1, score, check])\n",
    "            \n",
    "        # Printing\n",
    "        to_print.append([embed_name, scores.mean(), scores.std(), check])\n",
    "    to_print = pd.DataFrame(to_print, columns=['embed', 'r2_mean', 'r2_std', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10).reset_index(drop=True))\n",
    "    print('--------------------------------')\n",
    " \n",
    " \n",
    "rca = pd.DataFrame(rca, columns=['embed', 'norm', 'train_n', 'fold', 'r2', 'check'])\n",
    "rca.to_csv('../../data/final/rca_ensemb.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-08T10:05:30.717994Z",
     "start_time": "2024-08-08T10:04:54.476904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8e243a7f7b046b8aa85f5d4211783b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq_HAL:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.734332  0.014650  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.722789  0.014559  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.693546  0.017359  pass\n",
      "3                CBOW_GoogleNews  0.668775  0.011807  pass\n",
      "4                      morphoNLM  0.500359  0.041678  pass\n",
      "--------------------------------\n",
      "Freq_KF:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0  CBOW_GoogleNews&PPMI_SVD_SWOW  0.664336  0.018458  pass\n",
      "1      CBOW_GoogleNews&morphoNLM  0.661353  0.014110  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.626375  0.026625  pass\n",
      "3                CBOW_GoogleNews  0.610917  0.010366  pass\n",
      "4                      morphoNLM  0.415260  0.048085  pass\n",
      "--------------------------------\n",
      "Freq_SUBTLEXUS:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.735633  0.015040  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.730976  0.019344  pass\n",
      "2                CBOW_GoogleNews  0.673558  0.016496  pass\n",
      "3        morphoNLM&PPMI_SVD_SWOW  0.661628  0.023564  pass\n",
      "4                      morphoNLM  0.441110  0.034374  pass\n",
      "--------------------------------\n",
      "Freq_SUBTLEXUK:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.715433  0.017352  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.704482  0.020197  pass\n",
      "2                CBOW_GoogleNews  0.659742  0.021317  pass\n",
      "3        morphoNLM&PPMI_SVD_SWOW  0.616902  0.026001  pass\n",
      "4                      morphoNLM  0.417787  0.042920  pass\n",
      "--------------------------------\n",
      "Freq_Blog:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.750879  0.016900  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.746223  0.019248  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.695088  0.022315  pass\n",
      "3                CBOW_GoogleNews  0.686638  0.018623  pass\n",
      "4                      morphoNLM  0.463611  0.043349  pass\n",
      "--------------------------------\n",
      "Freq_Twitter:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m check \u001B[38;5;241m=\u001B[39m checker(solo_embed_names, y, norm_dtype, meta, outer_cv, norm_name)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 37\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[43mk_fold_cross_val\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m     scores \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mSeries([np\u001B[38;5;241m.\u001B[39mnan] \u001B[38;5;241m*\u001B[39m outer_cv)\n",
      "File \u001B[0;32m~/Documents/PycharmProjects/psychProbing/code/rca/rca.py:92\u001B[0m, in \u001B[0;36mk_fold_cross_val\u001B[0;34m(estim, X, y, outer_cv, scoring, n_jobs)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mk_fold_cross_val\u001B[39m(estim, X, y, outer_cv, scoring, n_jobs):\n\u001B[0;32m---> 92\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[43mcross_val_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    513\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 515\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    936\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 938\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    940\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
