{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from rca import process_categorical, best_logistic_solver, k_fold_cross_val, make_binary_scoring, make_multiclass_scoring, checker"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rca = pd.read_csv('../../data/results/rca.csv')\n",
    "meta = pd.read_csv('../../data/psychNorms/psychNorms_metadata.csv', index_col=0)\n",
    "norms = pd.read_csv('../../data/psychNorms/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "\n",
    "# Adding norm_cat to rca\n",
    "rca['norm_cat'] = (\n",
    "    rca['norm'].apply(lambda norm: meta.loc[norm]['category'])\n",
    "    .replace({'_': ' '}, regex=True)\n",
    ")\n",
    "\n",
    "rca = rca.query('test_n > 20 & embed != \"compo_attribs\"')\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:32:16.414561Z",
     "start_time": "2024-09-24T09:32:16.402492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_avgs = (\n",
    "    rca[['embed', 'norm_cat', 'r2_mean']]\n",
    "    .groupby(['embed', 'norm_cat']).median(numeric_only=True) # median is used to mitigate outliers within norm_cats\n",
    "    .groupby('embed').mean()\n",
    "    .rename(columns={'r2_mean': 'r2_avg'})\n",
    ")\n",
    "embed_avgs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            r2_avg\n",
       "embed                             \n",
       "CBOW_GoogleNews           0.451043\n",
       "EEG_speech               -0.065510\n",
       "EEG_text                 -0.048021\n",
       "GloVe_CommonCrawl         0.315571\n",
       "GloVe_Twitter             0.298494\n",
       "GloVe_Wikipedia           0.301758\n",
       "LexVec_CommonCrawl        0.293098\n",
       "PPMI_SVD_EAT              0.296026\n",
       "PPMI_SVD_SWOW             0.403018\n",
       "PPMI_SVD_SouthFlorida     0.253147\n",
       "SGSoftMaxInput_SWOW       0.349488\n",
       "SGSoftMaxOutput_SWOW      0.194071\n",
       "SVD_sim_rel               0.039614\n",
       "THINGS                    0.151472\n",
       "eye_tracking             -0.702208\n",
       "fMRI_speech_hyper_align  -0.008857\n",
       "fMRI_text_hyper_align    -0.130014\n",
       "fastTextSub_OpenSub       0.132329\n",
       "fastText_CommonCrawl      0.329448\n",
       "fastText_Wiki_News        0.311461\n",
       "microarray               -0.051168\n",
       "morphoNLM                 0.291309\n",
       "norms_sensorimotor        0.159089\n",
       "spherical_text_Wikipedia  0.309656"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embed</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CBOW_GoogleNews</th>\n",
       "      <td>0.451043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_speech</th>\n",
       "      <td>-0.065510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_text</th>\n",
       "      <td>-0.048021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_CommonCrawl</th>\n",
       "      <td>0.315571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_Twitter</th>\n",
       "      <td>0.298494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GloVe_Wikipedia</th>\n",
       "      <td>0.301758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LexVec_CommonCrawl</th>\n",
       "      <td>0.293098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPMI_SVD_EAT</th>\n",
       "      <td>0.296026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPMI_SVD_SWOW</th>\n",
       "      <td>0.403018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPMI_SVD_SouthFlorida</th>\n",
       "      <td>0.253147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGSoftMaxInput_SWOW</th>\n",
       "      <td>0.349488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGSoftMaxOutput_SWOW</th>\n",
       "      <td>0.194071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD_sim_rel</th>\n",
       "      <td>0.039614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THINGS</th>\n",
       "      <td>0.151472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eye_tracking</th>\n",
       "      <td>-0.702208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fMRI_speech_hyper_align</th>\n",
       "      <td>-0.008857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fMRI_text_hyper_align</th>\n",
       "      <td>-0.130014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastTextSub_OpenSub</th>\n",
       "      <td>0.132329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastText_CommonCrawl</th>\n",
       "      <td>0.329448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastText_Wiki_News</th>\n",
       "      <td>0.311461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microarray</th>\n",
       "      <td>-0.051168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morphoNLM</th>\n",
       "      <td>0.291309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norms_sensorimotor</th>\n",
       "      <td>0.159089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spherical_text_Wikipedia</th>\n",
       "      <td>0.309656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Adding embed types\n",
    "with open('../../data/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_avgs['type'] = embed_avgs.index.map(embed_to_type)\n",
    "\n",
    "# Finding top 2 text \n",
    "text_name_1, text_name_2 = (\n",
    "    embed_avgs.query('type == \"text\"').sort_values('r2_avg', ascending=False).head(2).index.tolist()\n",
    ")\n",
    "text_name_1, text_name_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:32:17.503598Z",
     "start_time": "2024-09-24T09:32:17.495433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CBOW_GoogleNews', 'fastText_CommonCrawl')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:32:19.108630Z",
     "start_time": "2024-09-24T09:32:19.103427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding top behavior\n",
    "behavior_name = (\n",
    "    embed_avgs.query('type == \"behavior\"').sort_values('r2_avg', ascending=False).head(1).index[0]\n",
    ")\n",
    "behavior_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PPMI_SVD_SWOW'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading embeds\n",
    "text_1 = pd.read_csv(f'../../data/embeds/{text_name_1}.csv', index_col=0)\n",
    "text_2 = pd.read_csv(f'../../data/embeds/{text_name_2}.csv', index_col=0)\n",
    "behavior = pd.read_csv(f'../../data/embeds/{behavior_name}.csv', index_col=0)\n",
    "\n",
    "# Aligning vocabs\n",
    "intersect = sorted(list(set.intersection(set(text_1.index), set(text_2.index), set(behavior.index))))\n",
    "text_1, text_2, behavior = text_1.loc[intersect], text_2.loc[intersect], behavior.loc[intersect]\n",
    "\n",
    "# Standardizing\n",
    "standardize = lambda df: (df - df.mean()) / df.std()\n",
    "text_1, text_2, behavior = standardize(text_1), standardize(text_2), standardize(behavior)\n",
    "\n",
    "# Ensembling for comparison\n",
    "embeds = {\n",
    "    text_name_1: text_1, \n",
    "    text_name_2: text_2,\n",
    "    text_name_1 + '&' + text_name_2: pd.concat([text_1, text_2], axis=1),\n",
    "    text_name_1 + '&' + behavior_name: pd.concat([text_1, behavior], axis=1),\n",
    "    text_name_2 + '&' + behavior_name: pd.concat([text_2, behavior], axis=1)\n",
    "}\n",
    "\n",
    "# Fixing column names\n",
    "for embed_name, embed in embeds.items():\n",
    "    embed.columns = list(range(embed.shape[1]))\n",
    "    embeds[embed_name] = embed\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T09:30:25.589562Z",
     "start_time": "2024-09-24T09:30:20.560006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBOW_GoogleNews': (11723, 300),\n",
       " 'fastText_CommonCrawl': (11723, 300),\n",
       " 'CBOW_GoogleNews&fastText_CommonCrawl': (11723, 600),\n",
       " 'CBOW_GoogleNews&PPMI_SVD_SWOW': (11723, 600),\n",
       " 'fastText_CommonCrawl&PPMI_SVD_SWOW': (11723, 600)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:30:56.209307Z",
     "start_time": "2024-09-24T09:30:54.495025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Changing associated_embed to more usable format\n",
    "meta['associated_embed'] = meta['associated_embed'].str.split(' ')\n",
    "\n",
    "# Log transforming selected norms\n",
    "norms_to_log = pd.read_csv('../../data/norms_to_log.csv')['norm']\n",
    "norms[norms_to_log] = norms[norms_to_log].apply(np.log1p)\n",
    "norms_to_log"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Nsenses_WordNet\n",
       "1           Nsenses_Wordsmyth\n",
       "2         Nmeanings_Wordsmyth\n",
       "3          Nmeanings_Websters\n",
       "4                   NFeatures\n",
       "5                       Sem_N\n",
       "6         Assoc_Freq_Token123\n",
       "7                 Cue_SetSize\n",
       "8           LexicalD_RT_V_ELP\n",
       "9           LexicalD_RT_V_ECP\n",
       "10          LexicalD_RT_V_BLP\n",
       "11         LexicalD_RT_A_MALD\n",
       "12         LexicalD_RT_A_AELP\n",
       "13              Naming_RT_ELP\n",
       "14       SemanticD_RT_Calgary\n",
       "15                  rt_khanna\n",
       "16                     rt_ley\n",
       "17               rt_chiarello\n",
       "18                    rt_chen\n",
       "19             aoa_rt_cortese\n",
       "20    imageability_rt_cortese\n",
       "21                  rt_schock\n",
       "Name: norm, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "min_ord, max_ord = -5, 5\n",
    "alphas = np.logspace(\n",
    "    min_ord, max_ord, max_ord - min_ord + 1\n",
    ")\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 6\n",
    "\n",
    "solo_embed_names = [text_name_1, text_name_2, behavior_name] # For checking data leakage in checker"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for norm_name in tqdm(norms.columns):\n",
    "    print(f'{norm_name}:')\n",
    "    y = norms[norm_name].dropna()\n",
    "    \n",
    "    to_print = []\n",
    "    for embed_name, embed in embeds.items():\n",
    "        \n",
    "        # Aligning embed with norm\n",
    "        X, y = embed.align(y, axis='index', join='inner', copy=True)\n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators ir categorical or continuous\n",
    "        if norm_dtype in ['binary', 'multiclass']: # categorical\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(y, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv), solver=solver\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "            \n",
    "        # Cross validation\n",
    "        associated_embed = meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(solo_embed_names, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs) # stratification is automatically used for classification\n",
    "            r2s, mses = scores['test_r2'], - scores['test_neg_mse']\n",
    "        else:\n",
    "            r2s, mses = pd.Series([np.nan] * outer_cv), pd.Series([np.nan] * outer_cv)\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(y))\n",
    "        for i, (r2, mse) in enumerate(zip(r2s, mses)):\n",
    "            rca.append([embed_name, norm_name, train_n, i + 1, r2, mse, check])\n",
    "            \n",
    "        # Printing\n",
    "        to_print.append([embed_name, r2s.mean(), r2s.std(), check])\n",
    "    to_print = pd.DataFrame(to_print, columns=['embed', 'r2_mean', 'r2_std', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10).reset_index(drop=True))\n",
    "    print('--------------------------------')\n",
    " \n",
    " \n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'norm', 'train_n', 'fold', 'r2', 'mse', 'check']\n",
    ")\n",
    "rca.to_csv('../../data/results/rca_ensemb.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
