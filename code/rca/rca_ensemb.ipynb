{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from rca import process_categorical, best_logistic_solver, k_fold_cross_val, make_binary_scoring, make_multiclass_scoring, checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:25.759027Z",
     "start_time": "2024-09-16T09:54:25.754838Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "rca = pd.read_csv('../../data/final/rca.csv')\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.092158Z",
     "start_time": "2024-09-16T09:54:27.070861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                embed embed_type                     norm  train_n  test_n  \\\n",
       "0     CBOW_GoogleNews       text                 Freq_HAL    28012    7003   \n",
       "1     CBOW_GoogleNews       text                  Freq_KF    19285    4822   \n",
       "2     CBOW_GoogleNews       text           Freq_SUBTLEXUS    28636    7159   \n",
       "3     CBOW_GoogleNews       text           Freq_SUBTLEXUK    29316    7330   \n",
       "4     CBOW_GoogleNews       text                Freq_Blog    31876    7969   \n",
       "...               ...        ...                      ...      ...     ...   \n",
       "7295           THINGS   behavior   familiarity_vanarsdall      376      95   \n",
       "7296           THINGS   behavior  imageability_vanarsdall      376      95   \n",
       "7297           THINGS   behavior         familiarity_fear      173      44   \n",
       "7298           THINGS   behavior                 aoa_fear      173      44   \n",
       "7299           THINGS   behavior        imageability_fear      173      44   \n",
       "\n",
       "        p   r2_mean     r2_sd     mse_mean      mse_sd check  \n",
       "0     300  0.522106  0.008390     2.715519    0.072449  pass  \n",
       "1     300  0.500385  0.009733     0.156678    0.004765  pass  \n",
       "2     300  0.537246  0.009834     0.361360    0.007800  pass  \n",
       "3     300  0.545626  0.008433     0.446059    0.009071  pass  \n",
       "4     300  0.523688  0.008467     0.400176    0.009336  pass  \n",
       "...   ...       ...       ...          ...         ...   ...  \n",
       "7295   49  0.060692  0.083942  3326.617511  620.203961  pass  \n",
       "7296   49  0.053593  0.095680  1345.018025  292.430129  pass  \n",
       "7297   49  0.139160  0.160894     0.790788    0.216911  pass  \n",
       "7298   49 -0.021206  0.121789     0.533727    0.039008  pass  \n",
       "7299   49 -0.054670  0.126442     0.270169    0.051645  pass  \n",
       "\n",
       "[7300 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed</th>\n",
       "      <th>embed_type</th>\n",
       "      <th>norm</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>p</th>\n",
       "      <th>r2_mean</th>\n",
       "      <th>r2_sd</th>\n",
       "      <th>mse_mean</th>\n",
       "      <th>mse_sd</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_HAL</td>\n",
       "      <td>28012</td>\n",
       "      <td>7003</td>\n",
       "      <td>300</td>\n",
       "      <td>0.522106</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>2.715519</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_KF</td>\n",
       "      <td>19285</td>\n",
       "      <td>4822</td>\n",
       "      <td>300</td>\n",
       "      <td>0.500385</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.156678</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUS</td>\n",
       "      <td>28636</td>\n",
       "      <td>7159</td>\n",
       "      <td>300</td>\n",
       "      <td>0.537246</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.361360</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_SUBTLEXUK</td>\n",
       "      <td>29316</td>\n",
       "      <td>7330</td>\n",
       "      <td>300</td>\n",
       "      <td>0.545626</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.446059</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBOW_GoogleNews</td>\n",
       "      <td>text</td>\n",
       "      <td>Freq_Blog</td>\n",
       "      <td>31876</td>\n",
       "      <td>7969</td>\n",
       "      <td>300</td>\n",
       "      <td>0.523688</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.400176</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>0.060692</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>3326.617511</td>\n",
       "      <td>620.203961</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_vanarsdall</td>\n",
       "      <td>376</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>1345.018025</td>\n",
       "      <td>292.430129</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>familiarity_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>0.139160</td>\n",
       "      <td>0.160894</td>\n",
       "      <td>0.790788</td>\n",
       "      <td>0.216911</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>aoa_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>0.121789</td>\n",
       "      <td>0.533727</td>\n",
       "      <td>0.039008</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>THINGS</td>\n",
       "      <td>behavior</td>\n",
       "      <td>imageability_fear</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.054670</td>\n",
       "      <td>0.126442</td>\n",
       "      <td>0.270169</td>\n",
       "      <td>0.051645</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7300 rows Ã— 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "embed_means = rca.groupby('embed').mean(numeric_only=True)\n",
    "\n",
    "# Adding embed types\n",
    "with open('../../data/raw/embed_to_dtype.json', 'r') as f:\n",
    "    embed_to_type = json.load(f)\n",
    "embed_means['type'] = embed_means.index.map(embed_to_type)\n",
    "\n",
    "# Finding top 2 text \n",
    "text_name_1, text_name_2 = (\n",
    "    embed_means.query('type == \"text\"').sort_values('r2_mean', ascending=False).head(2).index.tolist()\n",
    ")\n",
    "text_name_1, text_name_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.363397Z",
     "start_time": "2024-09-16T09:54:27.354472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CBOW_GoogleNews', 'morphoNLM')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:27.698454Z",
     "start_time": "2024-09-16T09:54:27.690651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Finding top behavior\n",
    "behavior_name = (\n",
    "    embed_means.query('type == \"behavior\"').sort_values('r2_mean', ascending=False).head(1).index[0]\n",
    ")\n",
    "behavior_name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PPMI_SVD_SWOW'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading embeds\n",
    "text_1 = pd.read_csv(f'../../data/raw/embeds/{text_name_1}.csv', index_col=0)\n",
    "text_2 = pd.read_csv(f'../../data/raw/embeds/{text_name_2}.csv', index_col=0)\n",
    "behavior = pd.read_csv(f'../../data/raw/embeds/{behavior_name}.csv', index_col=0)\n",
    "\n",
    "# Aligning vocabs\n",
    "intersect = sorted(list(set.intersection(set(text_1.index), set(text_2.index), set(behavior.index))))\n",
    "text_1, text_2, behavior = text_1.loc[intersect], text_2.loc[intersect], behavior.loc[intersect]\n",
    "\n",
    "# Standardizing\n",
    "standardize = lambda df: (df - df.mean()) / df.std()\n",
    "text_1, text_2, behavior = standardize(text_1), standardize(text_2), standardize(behavior)\n",
    "\n",
    "# Ensembling for comparison\n",
    "embeds = {\n",
    "    text_name_1: text_1, \n",
    "    text_name_2: text_2,\n",
    "    text_name_1 + '&' + text_name_2: pd.concat([text_1, text_2], axis=1),\n",
    "    text_name_1 + '&' + behavior_name: pd.concat([text_1, behavior], axis=1),\n",
    "    text_name_2 + '&' + behavior_name: pd.concat([text_2, behavior], axis=1)\n",
    "}\n",
    "\n",
    "# Fixing column names\n",
    "for embed_name, embed in embeds.items():\n",
    "    embed.columns = list(range(embed.shape[1]))\n",
    "    embeds[embed_name] = embed\n",
    "\n",
    "{name: embed.shape for name, embed in embeds.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:31.486298Z",
     "start_time": "2024-09-16T09:54:28.013607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBOW_GoogleNews': (11182, 300),\n",
       " 'morphoNLM': (11182, 50),\n",
       " 'CBOW_GoogleNews&morphoNLM': (11182, 350),\n",
       " 'CBOW_GoogleNews&PPMI_SVD_SWOW': (11182, 600),\n",
       " 'morphoNLM&PPMI_SVD_SWOW': (11182, 350)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "meta = pd.read_csv('../../data/raw/psychNorms_metadata.csv', index_col=0)\n",
    "meta['associated_embed'] = meta['associated_embed'].str.split(' ')\n",
    "\n",
    "norms = pd.read_csv('../../data/raw/psychNorms.zip', index_col=0, compression='zip', low_memory=False)\n",
    "norms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:33.389097Z",
     "start_time": "2024-09-16T09:54:31.487818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Freq_HAL  Freq_KF  Freq_SUBTLEXUS  Freq_SUBTLEXUK  Freq_Blog  \\\n",
       "'em               0.0      NaN             NaN             NaN        NaN   \n",
       "'neath            0.0      NaN             NaN             NaN        NaN   \n",
       "'re               0.0      NaN             NaN             NaN        NaN   \n",
       "'shun             0.0      NaN             NaN             NaN        NaN   \n",
       "'tis              0.0      NaN             NaN             NaN        NaN   \n",
       "...               ...      ...             ...             ...        ...   \n",
       "shrick            NaN      NaN             NaN             NaN        NaN   \n",
       "post office       NaN      NaN             NaN             NaN        NaN   \n",
       "fishing rod       NaN      NaN             NaN             NaN        NaN   \n",
       "March             NaN      NaN             NaN             NaN        NaN   \n",
       "May               NaN      NaN             NaN             NaN        NaN   \n",
       "\n",
       "             Freq_Twitter  Freq_News  Freq_CobW  Freq_CobS  CD_SUBTLEXUS  ...  \\\n",
       "'em                   NaN        NaN     1.3617     1.9138           NaN  ...   \n",
       "'neath                NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'re                   NaN        NaN     0.9031     1.6335           NaN  ...   \n",
       "'shun                 NaN        NaN     0.0000     0.0000           NaN  ...   \n",
       "'tis                  NaN        NaN     0.4771     0.6021           NaN  ...   \n",
       "...                   ...        ...        ...        ...           ...  ...   \n",
       "shrick                NaN        NaN        NaN        NaN           NaN  ...   \n",
       "post office           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "fishing rod           NaN        NaN        NaN        NaN           NaN  ...   \n",
       "March                 NaN        NaN        NaN        NaN           NaN  ...   \n",
       "May                   NaN        NaN        NaN        NaN           NaN  ...   \n",
       "\n",
       "             reproduction_vanarsdall  person_vanarsdall  goals_vanarsdall  \\\n",
       "'em                              NaN                NaN               NaN   \n",
       "'neath                           NaN                NaN               NaN   \n",
       "'re                              NaN                NaN               NaN   \n",
       "'shun                            NaN                NaN               NaN   \n",
       "'tis                             NaN                NaN               NaN   \n",
       "...                              ...                ...               ...   \n",
       "shrick                           NaN                NaN               NaN   \n",
       "post office                      NaN                NaN               NaN   \n",
       "fishing rod                      NaN                NaN               NaN   \n",
       "March                            NaN                NaN               NaN   \n",
       "May                              NaN                NaN               NaN   \n",
       "\n",
       "             movement_vanarsdall  concreteness_vanarsdall  \\\n",
       "'em                          NaN                      NaN   \n",
       "'neath                       NaN                      NaN   \n",
       "'re                          NaN                      NaN   \n",
       "'shun                        NaN                      NaN   \n",
       "'tis                         NaN                      NaN   \n",
       "...                          ...                      ...   \n",
       "shrick                       NaN                      NaN   \n",
       "post office                  NaN                      NaN   \n",
       "fishing rod                  NaN                      NaN   \n",
       "March                        NaN                      NaN   \n",
       "May                          NaN                      NaN   \n",
       "\n",
       "             familiarity_vanarsdall  imageability_vanarsdall  \\\n",
       "'em                             NaN                      NaN   \n",
       "'neath                          NaN                      NaN   \n",
       "'re                             NaN                      NaN   \n",
       "'shun                           NaN                      NaN   \n",
       "'tis                            NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "shrick                          NaN                      NaN   \n",
       "post office                     NaN                      NaN   \n",
       "fishing rod                     NaN                      NaN   \n",
       "March                           NaN                      NaN   \n",
       "May                             NaN                      NaN   \n",
       "\n",
       "             familiarity_fear  aoa_fear  imageability_fear  \n",
       "'em                       NaN       NaN                NaN  \n",
       "'neath                    NaN       NaN                NaN  \n",
       "'re                       NaN       NaN                NaN  \n",
       "'shun                     NaN       NaN                NaN  \n",
       "'tis                      NaN       NaN                NaN  \n",
       "...                       ...       ...                ...  \n",
       "shrick                   2.62      4.38               2.93  \n",
       "post office              3.79      3.07               5.29  \n",
       "fishing rod              2.29      3.38               5.64  \n",
       "March                    3.43      2.76               3.50  \n",
       "May                      4.10      2.86               2.79  \n",
       "\n",
       "[107085 rows x 292 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Freq_KF</th>\n",
       "      <th>Freq_SUBTLEXUS</th>\n",
       "      <th>Freq_SUBTLEXUK</th>\n",
       "      <th>Freq_Blog</th>\n",
       "      <th>Freq_Twitter</th>\n",
       "      <th>Freq_News</th>\n",
       "      <th>Freq_CobW</th>\n",
       "      <th>Freq_CobS</th>\n",
       "      <th>CD_SUBTLEXUS</th>\n",
       "      <th>...</th>\n",
       "      <th>reproduction_vanarsdall</th>\n",
       "      <th>person_vanarsdall</th>\n",
       "      <th>goals_vanarsdall</th>\n",
       "      <th>movement_vanarsdall</th>\n",
       "      <th>concreteness_vanarsdall</th>\n",
       "      <th>familiarity_vanarsdall</th>\n",
       "      <th>imageability_vanarsdall</th>\n",
       "      <th>familiarity_fear</th>\n",
       "      <th>aoa_fear</th>\n",
       "      <th>imageability_fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'em</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3617</td>\n",
       "      <td>1.9138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'neath</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'re</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>1.6335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'shun</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'tis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fishing rod</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.38</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>March</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107085 rows Ã— 292 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:33.991340Z",
     "start_time": "2024-09-16T09:54:33.389952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Log transforming selected norms\n",
    "with open('../../data/processed/norms_to_log.pkl', 'rb') as f:\n",
    "    norms_to_log = pickle.load(f)\n",
    "    norms[norms_to_log] = norms[norms_to_log].apply(np.log1p)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ridge\n",
    "alphas = np.logspace(-3, 3, 6)\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Logistic hyperparameters\n",
    "Cs = 1 / alphas\n",
    "inner_cv = 5\n",
    "penalty = 'l2'\n",
    "\n",
    "# Scorers\n",
    "binary_scoring = make_binary_scoring()\n",
    "multiclass_scoring = make_multiclass_scoring()\n",
    "continuous_scoring = {'r2': 'r2', 'neg_mse': 'neg_mean_squared_error'}\n",
    "\n",
    "# outer_cv setting \n",
    "outer_cv, n_jobs = 5, 6\n",
    "\n",
    "solo_embed_names = [text_name_1, text_name_2, behavior_name] # For checking data leakage in checker"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:54:37.069691Z",
     "start_time": "2024-09-16T09:54:37.063180Z"
    }
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# RCA\n",
    "rca = []\n",
    "for norm_name in tqdm(norms.columns):\n",
    "    print(f'{norm_name}:')\n",
    "    y = norms[norm_name].dropna()\n",
    "    \n",
    "    to_print = []\n",
    "    for embed_name, embed in embeds.items():\n",
    "        \n",
    "        # Aligning embed with norm\n",
    "        X, y = embed.align(y, axis='index', join='inner', copy=True)\n",
    "        \n",
    "        # Checking norm dtype \n",
    "        norm_dtype = meta.loc[norm_name, 'type']\n",
    "        \n",
    "        # Solvers, scoring, estimators ir categorical or continuous\n",
    "        if norm_dtype in ['binary', 'multiclass']: # categorical\n",
    "            X, y = process_categorical(outer_cv, inner_cv, X, y)\n",
    "            \n",
    "            # may have switched form multi to bin after processing\n",
    "            norm_dtype = 'binary' if len(y.unique()) == 2 else 'multiclass'\n",
    "            \n",
    "            # Cross validation settings for logistic regression\n",
    "            solver = best_logistic_solver(y, norm_dtype)\n",
    "            \n",
    "            # Defining logistic regression \n",
    "            estimator = LogisticRegressionCV(\n",
    "                Cs=Cs, penalty=penalty, cv=StratifiedKFold(inner_cv), solver=solver\n",
    "            )\n",
    "            scoring = binary_scoring if norm_dtype == 'binary' else multiclass_scoring\n",
    "        else: # continuous\n",
    "            estimator, scoring = ridge, continuous_scoring\n",
    "            \n",
    "        # Cross validation\n",
    "        associated_embed = meta.loc[norm_name, 'associated_embed']\n",
    "        check = checker(solo_embed_names, y, norm_dtype, associated_embed, outer_cv)\n",
    "        if check == 'pass':\n",
    "            scores = k_fold_cross_val(estimator, X, y, outer_cv, scoring, n_jobs)\n",
    "            r2s, mses = scores['test_r2'], - scores['test_neg_mse']\n",
    "        else:\n",
    "            r2s, mses = pd.Series([np.nan] * outer_cv), pd.Series([np.nan] * outer_cv)\n",
    "            \n",
    "        # Saving\n",
    "        train_n = int(((outer_cv - 1) / outer_cv) * len(y))\n",
    "        for i, (r2, mse) in enumerate(zip(r2s, mses)):\n",
    "            rca.append([embed_name, norm_name, train_n, i + 1, r2, mse, check])\n",
    "            \n",
    "        # Printing\n",
    "        to_print.append([embed_name, r2s.mean(), r2s.std(), check])\n",
    "    to_print = pd.DataFrame(to_print, columns=['embed', 'r2_mean', 'r2_std', 'check'])\n",
    "    print(to_print.sort_values('r2_mean', ascending=False).head(10).reset_index(drop=True))\n",
    "    print('--------------------------------')\n",
    " \n",
    " \n",
    "rca = pd.DataFrame(\n",
    "    rca, columns=[\n",
    "        'embed', 'norm', 'train_n', 'fold', 'r2', 'mse', 'check']\n",
    ")\n",
    "rca.to_csv('../../data/final/rca_ensemb.csv', index=False)\n",
    "rca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-16T09:55:00.744499Z",
     "start_time": "2024-09-16T09:54:37.835988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c070304a40dd4b65b8e2420a37172b4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq_HAL:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0      CBOW_GoogleNews&morphoNLM  0.734332  0.014650  pass\n",
      "1  CBOW_GoogleNews&PPMI_SVD_SWOW  0.722789  0.014559  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.693546  0.017359  pass\n",
      "3                CBOW_GoogleNews  0.668775  0.011807  pass\n",
      "4                      morphoNLM  0.500359  0.041678  pass\n",
      "--------------------------------\n",
      "Freq_KF:\n",
      "                           embed   r2_mean    r2_std check\n",
      "0  CBOW_GoogleNews&PPMI_SVD_SWOW  0.664336  0.018458  pass\n",
      "1      CBOW_GoogleNews&morphoNLM  0.661353  0.014110  pass\n",
      "2        morphoNLM&PPMI_SVD_SWOW  0.626375  0.026625  pass\n",
      "3                CBOW_GoogleNews  0.610917  0.010366  pass\n",
      "4                      morphoNLM  0.415260  0.048085  pass\n",
      "--------------------------------\n",
      "Freq_SUBTLEXUS:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m check \u001B[38;5;241m=\u001B[39m checker(solo_embed_names, y, norm_dtype, associated_embed, outer_cv)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpass\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 38\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[43mk_fold_cross_val\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m     r2s, mses \u001B[38;5;241m=\u001B[39m scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_r2\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;241m-\u001B[39m scores[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_neg_mse\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/PycharmProjects/psychProbing/code/rca/rca.py:101\u001B[0m, in \u001B[0;36mk_fold_cross_val\u001B[0;34m(estim, X, y, outer_cv, scoring, n_jobs)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mk_fold_cross_val\u001B[39m(estim, X, y, outer_cv, scoring, n_jobs):\n\u001B[0;32m--> 101\u001B[0m     scores \u001B[38;5;241m=\u001B[39m \u001B[43mcross_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mouter_cv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscoring\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscoring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scores\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 266\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_train_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_train_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_estimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43merror_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    936\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 938\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    940\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/PsychEmbeddings/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
